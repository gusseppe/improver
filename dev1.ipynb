{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(cache=False, client=<groq.resources.chat.completions.Completions object at 0x776f38b73810>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x776f38b65a90>, model_name='llama-3.1-8b-instant', temperature=1e-08, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv('env')\n",
    "llm_name = \"llama3-8b-8192\"\n",
    "llm_name = \"llama-3.1-8b-instant\"\n",
    "# llm_name = \"llama3-70b-8192\"\n",
    "# llm_name = \"mixtral-8x7b-32768\"\n",
    "# llm_name = \"gemma-7b-it\"\n",
    "\n",
    "# llm_name = \"phi3:14b\"\n",
    "# llm_name = \"phi3\"\n",
    "\n",
    "llm_generator = ChatGroq(cache=False, temperature=0.0, model_name=llm_name)\n",
    "# llm_generator = ChatOllama(model=llm_name, cache=False, temperature=0.0)  #\n",
    "llm_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm just a computer program, so I don't have feelings, but thank you for asking! I'm functioning properly and ready to help with any questions or tasks you may have. How about you? How's your day going so far?\", response_metadata={'token_usage': {'completion_time': 0.066666667, 'completion_tokens': 50, 'prompt_time': 0.003285454, 'prompt_tokens': 16, 'queue_time': None, 'total_time': 0.069952121, 'total_tokens': 66}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f66ccb39ec', 'finish_reason': 'stop', 'logprobs': None}, id='run-3c031335-c541-4699-bd0a-9c6304a68df9-0', usage_metadata={'input_tokens': 16, 'output_tokens': 50, 'total_tokens': 66})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_generator.invoke(\"Hello, how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class State(TypedDict):\n",
    "    input: str\n",
    "\n",
    "\n",
    "def step_1(state):\n",
    "    print(\"---Step 1---\")\n",
    "    pass\n",
    "\n",
    "\n",
    "def step_2(state):\n",
    "    print(\"---Step 2---\")\n",
    "    pass\n",
    "\n",
    "\n",
    "def step_3(state):\n",
    "    print(\"---Step 3---\")\n",
    "    pass\n",
    "\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"step_1\", step_1)\n",
    "builder.add_node(\"step_2\", step_2)\n",
    "builder.add_node(\"step_3\", step_3)\n",
    "builder.add_edge(START, \"step_1\")\n",
    "builder.add_edge(\"step_1\", \"step_2\")\n",
    "builder.add_edge(\"step_2\", \"step_3\")\n",
    "builder.add_edge(\"step_3\", END)\n",
    "\n",
    "# Set up memory\n",
    "memory = MemorySaver()\n",
    "\n",
    "# Add\n",
    "graph = builder.compile(checkpointer=memory, interrupt_before=[\"step_3\"])\n",
    "display(Image(graph.get_graph().draw_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'hello world'}\n",
      "---Step 1---\n",
      "---Step 2---\n",
      "---Step 3---\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "initial_input = {\"input\": \"hello world\"}\n",
    "\n",
    "# Thread\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Run the graph until the first interruption\n",
    "for event in graph.stream(initial_input, thread, stream_mode=\"values\"):\n",
    "    print(event)\n",
    "\n",
    "user_approval = input(\"Do you want to go to Step 3? (yes/no): \")\n",
    "\n",
    "if user_approval.lower() == \"yes\":\n",
    "    # If approved, continue the graph execution\n",
    "    for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "        print(event)\n",
    "else:\n",
    "    print(\"Operation cancelled by user.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "load_dotenv('env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_weather(location: str):\n",
    "    \"\"\"Call to get the current weather.\"\"\"\n",
    "    if location.lower() in [\"sf\", \"san francisco\"]:\n",
    "        return \"It's 60 degrees and foggy.\"\n",
    "    else:\n",
    "        return \"It's 90 degrees and sunny.\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_coolest_cities():\n",
    "    \"\"\"Get a list of coolest cities\"\"\"\n",
    "    return \"nyc, sf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [get_weather, get_coolest_cities]\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv('env')\n",
    "# llm_name = \"llama3-8b-8192\"\n",
    "llm_name = \"llama-3.1-8b-instant\"\n",
    "# llm_name = \"gemma2-9b-it\"\n",
    "# llm_name = \"llama-3.1-70b-versatile\"\n",
    "\n",
    "\n",
    "llm_generator = ChatGroq(cache=False, temperature=0.0, model_name=llm_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatGroq(cache=False, client=<groq.resources.chat.completions.Completions object at 0x7fb751e470d0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7fb751e581d0>, model_name='llama-3.1-8b-instant', temperature=1e-08, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'get_weather', 'description': 'Call to get the current weather.', 'parameters': {'type': 'object', 'properties': {'location': {'type': 'string'}}, 'required': ['location']}}}, {'type': 'function', 'function': {'name': 'get_coolest_cities', 'description': 'Get a list of coolest cities', 'parameters': {'type': 'object', 'properties': {}}}}]})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_tools = llm_generator.bind_tools(tools)\n",
    "model_with_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_61hb', 'function': {'arguments': '{}', 'name': 'get_coolest_cities'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_time': 0.08, 'completion_tokens': 60, 'prompt_time': 0.241760844, 'prompt_tokens': 969, 'queue_time': None, 'total_time': 0.321760844, 'total_tokens': 1029}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f66ccb39ec', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-dcd342da-a56c-43dd-af35-fbe129bf5d91-0', tool_calls=[{'name': 'get_coolest_cities', 'args': {}, 'id': 'call_61hb'}], usage_metadata={'input_tokens': 969, 'output_tokens': 60, 'total_tokens': 1029})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_tools.invoke(\"Get the coolest cities.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "load_dotenv('env')\n",
    "# llm_name = \"llama3-8b-8192\"\n",
    "llm_name = \"llama-3.1-8b-instant\"\n",
    "# llm_name = \"gemma2-9b-it\"\n",
    "# llm_name = \"llama-3.1-70b-versatile\"\n",
    "\n",
    "\n",
    "llm_generator = ChatGroq(cache=False, temperature=0.0, model_name=llm_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Any\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "class MonitoringAnalysisOutput(BaseModel):\n",
    "    update_arguments: List[str] = Field(description=\"List of arguments in favor of updating the model\")\n",
    "    keep_arguments: List[str] = Field(description=\"List of arguments in favor of keeping the current model\")\n",
    "\n",
    "class FastGraphState(BaseModel):\n",
    "    monitoring_report: str\n",
    "    monitoring_analysis: MonitoringAnalysisOutput = None\n",
    "    fast_tools_analysis: Dict[str, Any] = None\n",
    "    criticality_score: float = None\n",
    "    fast_update_result: Dict[str, Any] = None\n",
    "\n",
    "def analyze_monitoring_report(state: FastGraphState) -> FastGraphState:\n",
    "    # Initialize the language model\n",
    "    llm = llm_generator\n",
    "    \n",
    "    # Create the output parser\n",
    "    output_parser = PydanticOutputParser(pydantic_object=MonitoringAnalysisOutput)\n",
    "\n",
    "    # Create the prompt template\n",
    "    template = \"\"\"\n",
    "    You are an AI model monitoring expert. Analyze the following monitoring report and provide arguments for and against updating the model.\n",
    "\n",
    "    Monitoring Report:\n",
    "    {monitoring_report}\n",
    "\n",
    "    Based on this report, list the arguments for updating the model and for keeping the current model.\n",
    "\n",
    "    {format_instructions}\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    # Create the chain\n",
    "    chain = prompt | llm | output_parser\n",
    "\n",
    "    # Generate the analysis\n",
    "    result = chain.invoke({\n",
    "        \"monitoring_report\": state.monitoring_report,\n",
    "        \"format_instructions\": output_parser.get_format_instructions(),\n",
    "    })\n",
    "\n",
    "    # Update the state with the analysis result\n",
    "    state.monitoring_analysis = result\n",
    "    return state\n",
    "\n",
    "# Example usage in the graph\n",
    "graph = StateGraph(FastGraphState)\n",
    "graph.add_node(\"analyze_monitoring_report\", analyze_monitoring_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PGvector + Supabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_postgres import PGVector\n",
    "from langchain_postgres.vectorstores import PGVector\n",
    "\n",
    "# See docker command above to launch a postgres instance with pgvector enabled.\n",
    "connection = \"postgresql+psycopg://postgres:your-super-secret-and-long-postgres-password@localhost:5432/postgres\"  # Uses psycopg3!\n",
    "collection_name = \"my_docs\"\n",
    "\n",
    "\n",
    "vector_store = PGVector(\n",
    "    embeddings=embeddings,\n",
    "    collection_name=collection_name,\n",
    "    connection=connection,\n",
    "    use_jsonb=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List, Annotated\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "import operator\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "load_dotenv('env')\n",
    "# llm_name = \"llama3-8b-8192\"\n",
    "llm_name = \"llama-3.1-8b-instant\"\n",
    "# Define the state\n",
    "class AgentState(TypedDict):\n",
    "    requirements: str\n",
    "    plan: List[str]\n",
    "    elaborated_plan: str\n",
    "    email: str\n",
    "\n",
    "# Initialize the graph\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "# Create an LLM\n",
    "llm = ChatGroq(cache=False, temperature=0.0, model_name=llm_name)\n",
    "\n",
    "# Node 1: Understand requirements and make a plan\n",
    "def understand_and_plan(state: AgentState) -> AgentState:\n",
    "    prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    Based on the following project requirements, create a high-level plan with a list of tasks:\n",
    "\n",
    "    Requirements:\n",
    "    {requirements}\n",
    "\n",
    "    Output the plan as a list of tasks, each on a new line starting with an asterisk (*).\n",
    "    \"\"\")\n",
    "    chain = prompt | llm\n",
    "    response = chain.invoke({\"requirements\": state[\"requirements\"]})\n",
    "    return {\"plan\": response.content.strip().split(\"\\n\")}\n",
    "\n",
    "# Node 2: Elaborate on the plan\n",
    "def elaborate_plan(state: AgentState) -> AgentState:\n",
    "    prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    Given the following high-level plan:\n",
    "\n",
    "    {plan}\n",
    "\n",
    "    Elaborate on each task, providing more details and potential subtasks. \n",
    "    Include information about AI technologies, data processing, and security considerations where applicable.\n",
    "    \"\"\")\n",
    "    chain = prompt | llm\n",
    "    response = chain.invoke({\"plan\": \"\\n\".join(state[\"plan\"])})\n",
    "    return {\"elaborated_plan\": response.content}\n",
    "\n",
    "# Node 3: Write the proposal email\n",
    "def write_email(state: AgentState) -> AgentState:\n",
    "    prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    Using the elaborated plan below, write a professional proposal email to the client. \n",
    "    The email should be in markdown format and include:\n",
    "    1. A brief introduction\n",
    "    2. An overview of the project requirements\n",
    "    3. The list of tasks (use the original high-level plan for this)\n",
    "    4. A summary of the elaborated plan\n",
    "    5. A conclusion with next steps\n",
    "\n",
    "    Elaborated Plan:\n",
    "    {elaborated_plan}\n",
    "\n",
    "    Original Plan:\n",
    "    {original_plan}\n",
    "\n",
    "    Requirements:\n",
    "    {requirements}\n",
    "    \"\"\")\n",
    "    chain = prompt | llm\n",
    "    response = chain.invoke({\n",
    "        \"elaborated_plan\": state[\"elaborated_plan\"],\n",
    "        \"original_plan\": \"\\n\".join(state[\"plan\"]),\n",
    "        \"requirements\": state[\"requirements\"]\n",
    "    })\n",
    "    return {\"email\": response.content}\n",
    "\n",
    "# Add nodes to the graph\n",
    "graph.add_node(\"understand_and_plan\", understand_and_plan)\n",
    "graph.add_node(\"elaborate_plan\", elaborate_plan)\n",
    "graph.add_node(\"write_email\", write_email)\n",
    "\n",
    "# Add edges\n",
    "graph.add_edge(\"understand_and_plan\", \"elaborate_plan\")\n",
    "graph.add_edge(\"elaborate_plan\", \"write_email\")\n",
    "graph.add_edge(\"write_email\", END)\n",
    "\n",
    "# Set the entry point\n",
    "graph.set_entry_point(\"understand_and_plan\")\n",
    "\n",
    "# Compile the graph\n",
    "workflow = graph.compile()\n",
    "\n",
    "# Function to run the workflow\n",
    "def generate_proposal_email(requirements: str) -> str:\n",
    "    result = workflow.invoke({\"requirements\": requirements})\n",
    "    return result[\"email\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a professional proposal email to the client in markdown format:\n",
      "\n",
      "**Proposal for Financial Reporting and Recommendation System**\n",
      "\n",
      "**Introduction**\n",
      "===============\n",
      "\n",
      "Dear [Client],\n",
      "\n",
      "We are pleased to submit a proposal for the development of a financial reporting and recommendation system that meets your requirements. Our team has carefully reviewed the project requirements and has developed a comprehensive plan to deliver a secure, efficient, and effective system.\n",
      "\n",
      "**Project Overview**\n",
      "================\n",
      "\n",
      "The proposed system will generate client financial reports and recommend financial products (e.g., vehicular credit, mortgage credit) based on client data. The system will process data from multiple sources (tabular, JSON, PDFs, raw text) and operate in a secure, on-premise environment.\n",
      "\n",
      "**Task List**\n",
      "=============\n",
      "\n",
      "Here is a high-level list of tasks that our team will perform to deliver the system:\n",
      "\n",
      "1. **Define project scope and objectives**\n",
      "\t* Identify the types of financial reports to be generated\n",
      "\t* Determine the financial products to be recommended\n",
      "\t* Define the target audience for the system\n",
      "\t* Establish key performance indicators (KPIs) for the system\n",
      "\t* Develop a project timeline and budget\n",
      "2. **Design a data ingestion pipeline**\n",
      "\t* Identify the data sources to be ingested\n",
      "\t* Determine the data formats to be supported\n",
      "\t* Design a data processing workflow to handle data from multiple sources\n",
      "\t* Choose a data ingestion tool (e.g., Apache NiFi, AWS Glue)\n",
      "\t* Implement data validation and quality checks\n",
      "3. **Develop a data storage solution**\n",
      "\t* Choose a data storage solution (e.g., relational database, NoSQL database, data warehouse)\n",
      "\t* Design a data schema to store ingested data\n",
      "\t* Implement data encryption and access control\n",
      "\t* Choose a data storage tool (e.g., MySQL, MongoDB, Amazon Redshift)\n",
      "\t* Implement data backup and recovery procedures\n",
      "4. **Implement data processing and transformation logic**\n",
      "\t* Design a data processing workflow to transform ingested data into a usable format\n",
      "\t* Choose a data processing tool (e.g., Apache Spark, AWS Lambda)\n",
      "\t* Implement data validation and quality checks\n",
      "\t* Implement data aggregation and grouping\n",
      "\t* Choose a data transformation tool (e.g., Apache Beam, AWS Glue)\n",
      "5. **Design and implement a financial reporting module**\n",
      "\t* Choose a reporting tool (e.g., Tableau, Power BI, Apache Superset)\n",
      "\t* Design a reporting workflow to generate client financial reports\n",
      "\t* Implement data visualization and charting\n",
      "\t* Implement report scheduling and delivery\n",
      "\t* Choose a data storage solution for report data\n",
      "6. **Develop a recommendation engine**\n",
      "\t* Choose a recommendation engine tool (e.g., Apache Mahout, TensorFlow Recommenders)\n",
      "\t* Design a recommendation workflow to suggest financial products based on client data\n",
      "\t* Implement data preprocessing and feature engineering\n",
      "\t* Implement model training and evaluation\n",
      "\t* Choose a data storage solution for recommendation data\n",
      "7. **Implement security measures**\n",
      "\t* Choose a security framework (e.g., NIST Cybersecurity Framework, ISO 27001)\n",
      "\t* Implement access control and authentication\n",
      "\t* Implement data encryption and decryption\n",
      "\t* Implement network security measures (e.g., firewalls, intrusion detection)\n",
      "\t* Implement incident response and disaster recovery procedures\n",
      "8. **Develop a user interface**\n",
      "\t* Choose a user interface tool (e.g., React, Angular, Vue.js)\n",
      "\t* Design a user interface workflow to allow clients to access their financial reports and product recommendations\n",
      "\t* Implement user authentication and authorization\n",
      "\t* Implement data visualization and charting\n",
      "\t* Choose a data storage solution for user interface data\n",
      "9. **Conduct unit testing and integration testing**\n",
      "\t* Choose a testing framework (e.g., JUnit, PyUnit)\n",
      "\t* Implement unit tests for individual components\n",
      "\t* Implement integration tests for system components\n",
      "\t* Choose a testing tool (e.g., Selenium, Appium)\n",
      "\t* Implement test automation\n",
      "10. **Deploy the system**\n",
      "\t* Choose a deployment tool (e.g., Docker, Kubernetes)\n",
      "\t* Implement deployment scripts and workflows\n",
      "\t* Choose a cloud provider (e.g., AWS, Azure, Google Cloud)\n",
      "\t* Implement cloud security measures\n",
      "\t* Choose a monitoring and logging tool (e.g., Prometheus, Grafana)\n",
      "11. **Provide training and support**\n",
      "\t* Choose a training tool (e.g., online learning platform, instructor-led training)\n",
      "\t* Develop training materials and documentation\n",
      "\t* Implement support workflows and procedures\n",
      "\t* Choose a support tool (e.g., ticketing system, chatbot)\n",
      "\t* Implement knowledge management and documentation\n",
      "12. **Monitor and maintain the system**\n",
      "\t* Choose a monitoring tool (e.g., Prometheus, Grafana)\n",
      "\t* Implement monitoring workflows and procedures\n",
      "\t* Choose a logging tool (e.g., ELK Stack, Splunk)\n",
      "\t* Implement logging workflows and procedures\n",
      "\t* Choose a maintenance tool (e.g., Ansible, Puppet)\n",
      "\t* Implement maintenance workflows and procedures\n",
      "\n",
      "**Conclusion**\n",
      "==============\n",
      "\n",
      "Our team is confident that we can deliver a high-quality financial reporting and recommendation system that meets your requirements. We believe that our proposed plan is comprehensive and will ensure the successful delivery of the system.\n",
      "\n",
      "**Next Steps**\n",
      "==============\n",
      "\n",
      "We would like to schedule a meeting to discuss the proposal in more detail and answer any questions you may have. Please let us know a convenient time and date for you, and we will make sure to schedule it accordingly.\n",
      "\n",
      "Thank you for considering our proposal. We look forward to the opportunity to work with you.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]\n"
     ]
    }
   ],
   "source": [
    "requirements = \"\"\"\n",
    "* Generate client financial reports.\n",
    "* Recommend financial products (e.g., vehicular credit, mortgage credit).\n",
    "* Process data from multiple sources (tabular, JSON, PDFs, raw text).\n",
    "* Operate in a secure, on-premise environment.\n",
    "\"\"\"\n",
    "\n",
    "proposal_email = generate_proposal_email(requirements)\n",
    "print(proposal_email)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "    Dear Client,\n",
       "\n",
       "    Based on your requirements: Analyze customer data and provide recommendations\n",
       "\n",
       "    We propose the following tasks:\n",
       "    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. Analyze requirements\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. Develop solution\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. Test and deploy\n",
       "\n",
       "    Best regards,\n",
       "    AI Team\n",
       "    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "    Dear Client,\n",
       "\n",
       "    Based on your requirements: Analyze customer data and provide recommendations\n",
       "\n",
       "    We propose the following tasks:\n",
       "    \u001b[1;36m1\u001b[0m. Analyze requirements\n",
       "\u001b[1;36m2\u001b[0m. Develop solution\n",
       "\u001b[1;36m3\u001b[0m. Test and deploy\n",
       "\n",
       "    Best regards,\n",
       "    AI Team\n",
       "    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    requirements: str\n",
    "    email: str\n",
    "\n",
    "def write_email(state: AgentState) -> AgentState:\n",
    "    # Hardcoded tasks\n",
    "    tasks = \"1. Analyze requirements\\n2. Develop solution\\n3. Test and deploy\"\n",
    "    \n",
    "    # Simplified email writing\n",
    "    email = f\"\"\"\n",
    "    Dear Client,\n",
    "\n",
    "    Based on your requirements: {state['requirements']}\n",
    "\n",
    "    We propose the following tasks:\n",
    "    {tasks}\n",
    "\n",
    "    Best regards,\n",
    "    AI Team\n",
    "    \"\"\"\n",
    "    return {\"email\": email}\n",
    "\n",
    "# Initialize the graph\n",
    "graph = StateGraph(AgentState)\n",
    "graph.add_node(\"write_email\", write_email)\n",
    "graph.add_edge(\"write_email\", END)\n",
    "graph.set_entry_point(\"write_email\")\n",
    "\n",
    "workflow = graph.compile()\n",
    "\n",
    "# Function to run the workflow\n",
    "def generate_email(requirements: str) -> str:\n",
    "    result = workflow.invoke({\"requirements\": requirements})\n",
    "    return result[\"email\"]\n",
    "\n",
    "requirements = \"Analyze customer data and provide recommendations\"\n",
    "email = generate_email(requirements)\n",
    "print(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Dear Client,\n",
      "\n",
      "    Based on your requirements: Analyze customer data and provide recommendations\n",
      "\n",
      "    We propose the following tasks:\n",
      "    1. Analyze requirements\n",
      "2. Develop solution\n",
      "3. Test and deploy\n",
      "\n",
      "    Best regards,\n",
      "    AI Team\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    requirements: str\n",
    "    tasks: str\n",
    "    email: str\n",
    "\n",
    "def generate_tasks(state: AgentState) -> AgentState:\n",
    "    # Simplified task generation\n",
    "    tasks = \"1. Analyze requirements\\n2. Develop solution\\n3. Test and deploy\"\n",
    "    return {\"tasks\": tasks}\n",
    "\n",
    "def write_email(state: AgentState) -> AgentState:\n",
    "    # Simplified email writing\n",
    "    email = f\"\"\"\n",
    "    Dear Client,\n",
    "\n",
    "    Based on your requirements: {state['requirements']}\n",
    "\n",
    "    We propose the following tasks:\n",
    "    {state['tasks']}\n",
    "\n",
    "    Best regards,\n",
    "    AI Team\n",
    "    \"\"\"\n",
    "    return {\"email\": email}\n",
    "\n",
    "# Initialize the graph\n",
    "graph = StateGraph(AgentState)\n",
    "graph.add_node(\"generate_tasks\", generate_tasks)\n",
    "graph.add_node(\"write_email\", write_email)\n",
    "graph.add_edge(\"generate_tasks\", \"write_email\")\n",
    "graph.add_edge(\"write_email\", END)\n",
    "graph.set_entry_point(\"generate_tasks\")\n",
    "\n",
    "workflow = graph.compile()\n",
    "\n",
    "# Function to run the workflow\n",
    "def generate_email(requirements: str) -> str:\n",
    "    result = workflow.invoke({\"requirements\": requirements})\n",
    "    return result[\"email\"]\n",
    "\n",
    "requirements = \"Analyze customer data and provide recommendations\"\n",
    "email = generate_email(requirements)\n",
    "print(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = [\n",
    "    {\n",
    "        \"input\": \"Develop a website with user authentication\",\n",
    "        \"output\": \"\"\"\n",
    "        Dear Client,\n",
    "\n",
    "        Based on your requirements: Develop a website with user authentication\n",
    "\n",
    "        We propose the following tasks:\n",
    "        1. Design user authentication system\n",
    "        2. Develop frontend and backend\n",
    "        3. Implement security measures\n",
    "        4. Test and deploy website\n",
    "\n",
    "        Best regards,\n",
    "        AI Team\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Create a mobile app for task management\",\n",
    "        \"output\": \"\"\"\n",
    "        Dear Client,\n",
    "\n",
    "        Based on your requirements: Create a mobile app for task management\n",
    "\n",
    "        We propose the following tasks:\n",
    "        1. Design app UI/UX\n",
    "        2. Develop task management features\n",
    "        3. Implement data synchronization\n",
    "        4. Test on multiple devices\n",
    "        5. Deploy to app stores\n",
    "\n",
    "        Best regards,\n",
    "        AI Team\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Set up a data analytics pipeline\",\n",
    "        \"output\": \"\"\"\n",
    "        Dear Client,\n",
    "\n",
    "        Based on your requirements: Set up a data analytics pipeline\n",
    "\n",
    "        We propose the following tasks:\n",
    "        1. Analyze data sources and requirements\n",
    "        2. Design data pipeline architecture\n",
    "        3. Implement data collection and processing\n",
    "        4. Set up analytics and visualization tools\n",
    "        5. Test and optimize pipeline performance\n",
    "\n",
    "        Best regards,\n",
    "        AI Team\n",
    "        \"\"\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Iteration <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Iteration \u001b[1;36m1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Processing example <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Processing example \u001b[1;36m1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Raw LLM response:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Raw LLM response:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Here are the comparisons between the generated output and the ground truth output:\n",
       "\n",
       "**generate_tasks score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span>**\n",
       "**generate_tasks feedback:** The generated tasks are incomplete and lack specificity. While the ground truth output\n",
       "includes four tasks, the generated output only includes three tasks that are not as detailed. The task <span style=\"color: #008000; text-decoration-color: #008000\">\"Analyze </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">requirements\"</span> is a good start, but the other tasks are too vague and do not accurately reflect the requirements of \n",
       "developing a website with user authentication.\n",
       "\n",
       "**write_email score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8</span>**\n",
       "**write_email feedback:** The generated email is well-structured and includes a clear proposal based on the \n",
       "client's requirements. However, the tone is somewhat generic and lacks personalization. The ground truth output \n",
       "includes a more detailed and specific proposal, including the implementation of security measures, which is an \n",
       "important aspect of user authentication. Additionally, the ground truth output includes a more formal closing \n",
       "<span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Best regards, AI Team\"</span><span style=\"font-weight: bold\">)</span> compared to the generated output <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Best regards, AI Team\"</span> is not even present in the \n",
       "generated output, but it's assumed to be the same<span style=\"font-weight: bold\">)</span>.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Here are the comparisons between the generated output and the ground truth output:\n",
       "\n",
       "**generate_tasks score: \u001b[1;36m0.5\u001b[0m**\n",
       "**generate_tasks feedback:** The generated tasks are incomplete and lack specificity. While the ground truth output\n",
       "includes four tasks, the generated output only includes three tasks that are not as detailed. The task \u001b[32m\"Analyze \u001b[0m\n",
       "\u001b[32mrequirements\"\u001b[0m is a good start, but the other tasks are too vague and do not accurately reflect the requirements of \n",
       "developing a website with user authentication.\n",
       "\n",
       "**write_email score: \u001b[1;36m0.8\u001b[0m**\n",
       "**write_email feedback:** The generated email is well-structured and includes a clear proposal based on the \n",
       "client's requirements. However, the tone is somewhat generic and lacks personalization. The ground truth output \n",
       "includes a more detailed and specific proposal, including the implementation of security measures, which is an \n",
       "important aspect of user authentication. Additionally, the ground truth output includes a more formal closing \n",
       "\u001b[1m(\u001b[0m\u001b[32m\"Best regards, AI Team\"\u001b[0m\u001b[1m)\u001b[0m compared to the generated output \u001b[1m(\u001b[0m\u001b[32m\"Best regards, AI Team\"\u001b[0m is not even present in the \n",
       "generated output, but it's assumed to be the same\u001b[1m)\u001b[0m.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Warning: Could not parse score for generate_tasks. Using default score of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Warning: Could not parse score for generate_tasks. Using default score of \u001b[1;36m0.5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Warning: Could not parse score for write_email. Using default score of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Warning: Could not parse score for write_email. Using default score of \u001b[1;36m0.5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Processing example <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Processing example \u001b[1;36m2\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Raw LLM response:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Raw LLM response:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Here are the comparisons between the generated output and the ground truth output:\n",
       "\n",
       "**generate_tasks score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6</span>**\n",
       "**generate_tasks feedback:** The generated tasks are partially correct, but they lack some essential tasks that are\n",
       "typically involved in developing a mobile app for task management. The tasks <span style=\"color: #008000; text-decoration-color: #008000\">\"Analyze requirements\"</span> and <span style=\"color: #008000; text-decoration-color: #008000\">\"Test and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">deploy\"</span> are correct, but the tasks <span style=\"color: #008000; text-decoration-color: #008000\">\"Design app UI/UX\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"Develop task management features\"</span>, and <span style=\"color: #008000; text-decoration-color: #008000\">\"Implement data </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">synchronization\"</span> are missing. Additionally, the task <span style=\"color: #008000; text-decoration-color: #008000\">\"Test on multiple devices\"</span> is correct, but it's not as \n",
       "comprehensive as the ground truth output, which includes testing on multiple devices.\n",
       "\n",
       "**write_email score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8</span>**\n",
       "**write_email feedback:** The generated email is mostly correct, with a proper greeting, introduction, and closing.\n",
       "However, the body of the email is not as detailed as the ground truth output, which provides a more comprehensive \n",
       "list of proposed tasks. The tone and language used in the generated email are also somewhat generic and lack the \n",
       "specificity of the ground truth output.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Here are the comparisons between the generated output and the ground truth output:\n",
       "\n",
       "**generate_tasks score: \u001b[1;36m0.6\u001b[0m**\n",
       "**generate_tasks feedback:** The generated tasks are partially correct, but they lack some essential tasks that are\n",
       "typically involved in developing a mobile app for task management. The tasks \u001b[32m\"Analyze requirements\"\u001b[0m and \u001b[32m\"Test and \u001b[0m\n",
       "\u001b[32mdeploy\"\u001b[0m are correct, but the tasks \u001b[32m\"Design app UI/UX\"\u001b[0m, \u001b[32m\"Develop task management features\"\u001b[0m, and \u001b[32m\"Implement data \u001b[0m\n",
       "\u001b[32msynchronization\"\u001b[0m are missing. Additionally, the task \u001b[32m\"Test on multiple devices\"\u001b[0m is correct, but it's not as \n",
       "comprehensive as the ground truth output, which includes testing on multiple devices.\n",
       "\n",
       "**write_email score: \u001b[1;36m0.8\u001b[0m**\n",
       "**write_email feedback:** The generated email is mostly correct, with a proper greeting, introduction, and closing.\n",
       "However, the body of the email is not as detailed as the ground truth output, which provides a more comprehensive \n",
       "list of proposed tasks. The tone and language used in the generated email are also somewhat generic and lack the \n",
       "specificity of the ground truth output.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Warning: Could not parse score for generate_tasks. Using default score of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Warning: Could not parse score for generate_tasks. Using default score of \u001b[1;36m0.5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Warning: Could not parse score for write_email. Using default score of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Warning: Could not parse score for write_email. Using default score of \u001b[1;36m0.5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Processing example <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Processing example \u001b[1;36m3\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Raw LLM response:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Raw LLM response:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Here are the comparisons between the generated output and the ground truth output:\n",
       "\n",
       "**generate_tasks score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6</span>**\n",
       "**generate_tasks feedback:** The generated tasks are incomplete and lack specificity. While the first three tasks \n",
       "are somewhat related to data analytics, they are not as detailed or accurate as the ground truth output. The ground\n",
       "truth output includes tasks such as <span style=\"color: #008000; text-decoration-color: #008000\">\"Analyze data sources and requirements\"</span> and <span style=\"color: #008000; text-decoration-color: #008000\">\"Implement data collection and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">processing\"</span>, which are more specific and relevant to setting up a data analytics pipeline.\n",
       "\n",
       "**write_email score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8</span>**\n",
       "**write_email feedback:** The generated email is mostly accurate, with the correct greeting, introduction, and \n",
       "closing. However, the body of the email is somewhat generic and lacks the level of detail and specificity found in \n",
       "the ground truth output. The ground truth output includes more specific language and details about the proposed \n",
       "tasks, which would likely be more effective in communicating the AI team's proposal to the client.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Here are the comparisons between the generated output and the ground truth output:\n",
       "\n",
       "**generate_tasks score: \u001b[1;36m0.6\u001b[0m**\n",
       "**generate_tasks feedback:** The generated tasks are incomplete and lack specificity. While the first three tasks \n",
       "are somewhat related to data analytics, they are not as detailed or accurate as the ground truth output. The ground\n",
       "truth output includes tasks such as \u001b[32m\"Analyze data sources and requirements\"\u001b[0m and \u001b[32m\"Implement data collection and \u001b[0m\n",
       "\u001b[32mprocessing\"\u001b[0m, which are more specific and relevant to setting up a data analytics pipeline.\n",
       "\n",
       "**write_email score: \u001b[1;36m0.8\u001b[0m**\n",
       "**write_email feedback:** The generated email is mostly accurate, with the correct greeting, introduction, and \n",
       "closing. However, the body of the email is somewhat generic and lacks the level of detail and specificity found in \n",
       "the ground truth output. The ground truth output includes more specific language and details about the proposed \n",
       "tasks, which would likely be more effective in communicating the AI team's proposal to the client.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Warning: Could not parse score for generate_tasks. Using default score of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Warning: Could not parse score for generate_tasks. Using default score of \u001b[1;36m0.5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Warning: Could not parse score for write_email. Using default score of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Warning: Could not parse score for write_email. Using default score of \u001b[1;36m0.5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Updated generate_tasks\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Updated generate_tasks\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Updated write_email\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Updated write_email\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Iteration <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Iteration \u001b[1;36m2\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Processing example <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Processing example \u001b[1;36m1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Error processing example <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: invalid syntax <span style=\"font-weight: bold\">(&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">string</span><span style=\"font-weight: bold\">&gt;</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Error processing example \u001b[1;36m1\u001b[0m: invalid syntax \u001b[1m(\u001b[0m\u001b[1m<\u001b[0m\u001b[1;95mstring\u001b[0m\u001b[1m>\u001b[0m, line \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Processing example <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Processing example \u001b[1;36m2\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Error processing example <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: invalid syntax <span style=\"font-weight: bold\">(&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">string</span><span style=\"font-weight: bold\">&gt;</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Error processing example \u001b[1;36m2\u001b[0m: invalid syntax \u001b[1m(\u001b[0m\u001b[1m<\u001b[0m\u001b[1;95mstring\u001b[0m\u001b[1m>\u001b[0m, line \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Processing example <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Processing example \u001b[1;36m3\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Error processing example <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: invalid syntax <span style=\"font-weight: bold\">(&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">string</span><span style=\"font-weight: bold\">&gt;</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Error processing example \u001b[1;36m3\u001b[0m: invalid syntax \u001b[1m(\u001b[0m\u001b[1m<\u001b[0m\u001b[1;95mstring\u001b[0m\u001b[1m>\u001b[0m, line \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Updated generate_tasks\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Updated generate_tasks\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Updated write_email\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Updated write_email\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Iteration <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Iteration \u001b[1;36m3\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Processing example <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Processing example \u001b[1;36m1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Error processing example <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: invalid syntax <span style=\"font-weight: bold\">(&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">string</span><span style=\"font-weight: bold\">&gt;</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Error processing example \u001b[1;36m1\u001b[0m: invalid syntax \u001b[1m(\u001b[0m\u001b[1m<\u001b[0m\u001b[1;95mstring\u001b[0m\u001b[1m>\u001b[0m, line \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Processing example <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Processing example \u001b[1;36m2\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Error processing example <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: invalid syntax <span style=\"font-weight: bold\">(&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">string</span><span style=\"font-weight: bold\">&gt;</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Error processing example \u001b[1;36m2\u001b[0m: invalid syntax \u001b[1m(\u001b[0m\u001b[1m<\u001b[0m\u001b[1;95mstring\u001b[0m\u001b[1m>\u001b[0m, line \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Processing example <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Processing example \u001b[1;36m3\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Error processing example <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: invalid syntax <span style=\"font-weight: bold\">(&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">string</span><span style=\"font-weight: bold\">&gt;</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Error processing example \u001b[1;36m3\u001b[0m: invalid syntax \u001b[1m(\u001b[0m\u001b[1m<\u001b[0m\u001b[1;95mstring\u001b[0m\u001b[1m>\u001b[0m, line \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Updated generate_tasks\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Updated generate_tasks\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Updated write_email\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Updated write_email\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich import print\n",
    "import inspect\n",
    "from typing import List, Dict\n",
    "from langgraph.graph import StateGraph\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "class GraphAgentOptimizer:\n",
    "    def __init__(self, original_graph: StateGraph, ground_truth: List[Dict[str, str]], llm):\n",
    "        self.original_graph = original_graph\n",
    "        self.ground_truth = ground_truth\n",
    "        self.llm = llm\n",
    "        self.node_functions = {}\n",
    "        self.node_performances = {}\n",
    "\n",
    "    def load_graph(self):\n",
    "        for node_name, node_func in self.original_graph.nodes.items():\n",
    "            self.node_functions[node_name] = self.extract_function_source(node_func)\n",
    "            self.node_performances[node_name] = {'score': 0, 'feedback': ''}\n",
    "\n",
    "    def extract_function_source(self, func):\n",
    "        if hasattr(func, 'func'):  # For RunnableCallable objects\n",
    "            return inspect.getsource(func.func)\n",
    "        elif callable(func):\n",
    "            return inspect.getsource(func)\n",
    "        else:\n",
    "            return str(func)  # Fallback for other types\n",
    "\n",
    "    def optimize(self, num_iterations: int):\n",
    "        for iteration in range(num_iterations):\n",
    "            print(f\"Iteration {iteration + 1}\")\n",
    "            for i, example in enumerate(self.ground_truth):\n",
    "                print(f\"  Processing example {i + 1}\")\n",
    "                try:\n",
    "                    output = self.forward_pass(example['input'])\n",
    "                    self.evaluate_and_update(output, example['output'])\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing example {i + 1}: {str(e)}\")\n",
    "            self.update_node_functions()\n",
    "\n",
    "    def forward_pass(self, input_data: str) -> str:\n",
    "        state = {'requirements': input_data}\n",
    "        for node_name in ['generate_tasks', 'write_email']:\n",
    "            node_func = self.get_node_function(node_name)\n",
    "            state.update(node_func(state))\n",
    "        return state['email']\n",
    "\n",
    "    def evaluate_and_update(self, generated_output: str, ground_truth_output: str):\n",
    "        prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        Compare the generated output with the ground truth output.\n",
    "        Provide a score from 0 to 1 for each node (generate_tasks and write_email),\n",
    "        where 1 is perfect and 0 is completely wrong.\n",
    "        Also provide a brief explanation for each score.\n",
    "\n",
    "        Generated output:\n",
    "        {generated_output}\n",
    "\n",
    "        Ground truth output:\n",
    "        {ground_truth_output}\n",
    "\n",
    "        Response format:\n",
    "        generate_tasks score: [score]\n",
    "        generate_tasks feedback: [feedback]\n",
    "        write_email score: [score]\n",
    "        write_email feedback: [feedback]\n",
    "        \"\"\")\n",
    "        chain = prompt | self.llm\n",
    "        response = chain.invoke({\n",
    "            \"generated_output\": generated_output,\n",
    "            \"ground_truth_output\": ground_truth_output\n",
    "        })\n",
    "\n",
    "        print(\"Raw LLM response:\")\n",
    "        print(response.content)\n",
    "        \n",
    "        lines = response.content.split('\\n')\n",
    "        for node in ['generate_tasks', 'write_email']:\n",
    "            score_line = next((line for line in lines if f\"{node} score:\" in line), None)\n",
    "            feedback_line = next((line for line in lines if f\"{node} feedback:\" in line), None)\n",
    "            \n",
    "            if score_line and feedback_line:\n",
    "                try:\n",
    "                    score = float(score_line.split(':')[1].strip())\n",
    "                except ValueError:\n",
    "                    print(f\"Warning: Could not parse score for {node}. Using default score of 0.5\")\n",
    "                    score = 0.5\n",
    "                \n",
    "                feedback = feedback_line.split(':', 1)[1].strip() if ':' in feedback_line else ''\n",
    "                \n",
    "                self.node_performances[node]['score'] = (self.node_performances[node]['score'] + score) / 2\n",
    "                self.node_performances[node]['feedback'] += feedback + '\\n'\n",
    "            else:\n",
    "                print(f\"Warning: Could not find score or feedback for {node}\")\n",
    "\n",
    "    def update_node_functions(self):\n",
    "        for node_name, performance in self.node_performances.items():\n",
    "            if performance['score'] < 0.8:\n",
    "                prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "                Improve the following function based on the feedback:\n",
    "\n",
    "                Original function:\n",
    "                {original_function}\n",
    "\n",
    "                Performance score: {score}\n",
    "                Feedback: {feedback}\n",
    "\n",
    "                Generate an improved Python function:\n",
    "                \"\"\")\n",
    "                chain = prompt | self.llm\n",
    "                response = chain.invoke({\n",
    "                    \"original_function\": self.node_functions[node_name],\n",
    "                    \"score\": performance['score'],\n",
    "                    \"feedback\": performance['feedback']\n",
    "                })\n",
    "                self.node_functions[node_name] = response.content\n",
    "                print(f\"Updated {node_name}\")\n",
    "\n",
    "    def get_node_function(self, node_name: str) -> callable:\n",
    "        function_code = self.node_functions[node_name]\n",
    "        exec(function_code, globals())\n",
    "        return eval(node_name)\n",
    "# Usage\n",
    "# llm_name = \"llama-3.1-70b-versatile\"\n",
    "llm_name = \"llama-3.1-8b-instant\"\n",
    "\n",
    "llm = ChatGroq(cache=False, temperature=0.0, model_name=llm_name)\n",
    "optimizer = GraphAgentOptimizer(graph, ground_truth, llm)\n",
    "optimizer.load_graph()\n",
    "optimizer.optimize(num_iterations=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Based on the feedback, here's an improved version of the function:\n",
       "\n",
       "```python\n",
       "def <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">write_email</span><span style=\"font-weight: bold\">(</span>state: AgentState<span style=\"font-weight: bold\">)</span> -&gt; AgentState:\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>\"\n",
       "    Generate a detailed email proposal based on the client's requirements.\n",
       "\n",
       "    Args:\n",
       "        state <span style=\"font-weight: bold\">(</span>AgentState<span style=\"font-weight: bold\">)</span>: The current state of the agent, including the client's requirements and proposed tasks.\n",
       "\n",
       "    Returns:\n",
       "        AgentState: The updated state with the generated email.\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>\"\n",
       "    email = f\"<span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>\n",
       "    Dear <span style=\"font-weight: bold\">{</span>state<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'client_name'</span><span style=\"font-weight: bold\">]}</span>,\n",
       "\n",
       "    We are thrilled to have the opportunity to work with you on your user authentication project. Our team has \n",
       "carefully reviewed your requirements and developed a comprehensive proposal to ensure a secure and efficient user \n",
       "authentication process.\n",
       "\n",
       "    Our proposal includes the following key components:\n",
       "\n",
       "    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. **Multi-Factor Authentication**: We will implement a robust multi-factor authentication system, utilizing a \n",
       "combination of password, biometric, and token-based authentication methods to prevent unauthorized access. This \n",
       "will include:\n",
       "        * Password authentication with a minimum length of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> characters and a mix of uppercase, lowercase, \n",
       "numbers, and special characters.\n",
       "        * Biometric authentication using facial recognition, fingerprint scanning, or voice recognition.\n",
       "        * Token-based authentication using one-time passwords <span style=\"font-weight: bold\">(</span>OTPs<span style=\"font-weight: bold\">)</span> or time-based one-time passwords <span style=\"font-weight: bold\">(</span>TOTPs<span style=\"font-weight: bold\">)</span>.\n",
       "    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. **End-to-End Encryption**: We will use end-to-end encryption to protect user data, ensuring that it remains \n",
       "confidential and secure throughout the authentication process. This will include:\n",
       "        * Encrypting user data using AES-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span> encryption.\n",
       "        * Using secure protocols such as HTTPS and SFTP for data transfer.\n",
       "    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. **Regular Security Audits**: We will conduct regular security audits to identify and address potential \n",
       "vulnerabilities, ensuring that your user authentication system remains secure and up-to-date. This will include:\n",
       "        * Quarterly security audits to identify vulnerabilities and weaknesses.\n",
       "        * Regular software updates and patches to ensure the system remains secure.\n",
       "    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>. **Clear Instructions and Guidelines**: We will provide clear instructions and guidelines for users to \n",
       "follow, ensuring that they understand the authentication process and can navigate it easily. This will include:\n",
       "        * User manuals and guides for each authentication method.\n",
       "        * Regular training sessions for users to ensure they understand the authentication process.\n",
       "\n",
       "    We believe that these components will help us deliver a high-quality user authentication system that meets your\n",
       "needs and exceeds your expectations.\n",
       "\n",
       "    If you have any questions or would like to discuss our proposal in more detail, please do not hesitate to \n",
       "contact us.\n",
       "\n",
       "    Best regards,\n",
       "    AI Team\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>\"\n",
       "    return <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"email\"</span>: email<span style=\"font-weight: bold\">}</span>\n",
       "```\n",
       "\n",
       "Changes made:\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. Added a more formal greeting with the client's name.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. Provided a more detailed and specific proposal, including the implementation of security measures.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. Used more formal language and a more comprehensive list of proposed tasks.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>. Included a more detailed closing with the AI team's name.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>. Added a sentence to express appreciation for the opportunity to work with the client.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>. Emphasized the key components of the proposal to make it clearer and more concise.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>. Added a sentence to invite the client to discuss the proposal in more detail.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>. Added more specific details about the proposed tasks, such as the implementation of password authentication, \n",
       "biometric authentication, and token-based authentication.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>. Added more specific details about the end-to-end encryption, such as the use of AES-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span> encryption and secure \n",
       "protocols.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>. Added more specific details about the regular security audits, such as the frequency of audits and the types of\n",
       "updates and patches that will be applied.\n",
       "\n",
       "Note that I've assumed the `AgentState` object has the following attributes: `client_name`, `requirements`, and \n",
       "`tasks`. You may need to adjust the code to match your actual data structure.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Based on the feedback, here's an improved version of the function:\n",
       "\n",
       "```python\n",
       "def \u001b[1;35mwrite_email\u001b[0m\u001b[1m(\u001b[0mstate: AgentState\u001b[1m)\u001b[0m -> AgentState:\n",
       "    \u001b[32m\"\"\u001b[0m\"\n",
       "    Generate a detailed email proposal based on the client's requirements.\n",
       "\n",
       "    Args:\n",
       "        state \u001b[1m(\u001b[0mAgentState\u001b[1m)\u001b[0m: The current state of the agent, including the client's requirements and proposed tasks.\n",
       "\n",
       "    Returns:\n",
       "        AgentState: The updated state with the generated email.\n",
       "    \u001b[32m\"\"\u001b[0m\"\n",
       "    email = f\"\u001b[32m\"\"\u001b[0m\n",
       "    Dear \u001b[1m{\u001b[0mstate\u001b[1m[\u001b[0m\u001b[32m'client_name'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m,\n",
       "\n",
       "    We are thrilled to have the opportunity to work with you on your user authentication project. Our team has \n",
       "carefully reviewed your requirements and developed a comprehensive proposal to ensure a secure and efficient user \n",
       "authentication process.\n",
       "\n",
       "    Our proposal includes the following key components:\n",
       "\n",
       "    \u001b[1;36m1\u001b[0m. **Multi-Factor Authentication**: We will implement a robust multi-factor authentication system, utilizing a \n",
       "combination of password, biometric, and token-based authentication methods to prevent unauthorized access. This \n",
       "will include:\n",
       "        * Password authentication with a minimum length of \u001b[1;36m12\u001b[0m characters and a mix of uppercase, lowercase, \n",
       "numbers, and special characters.\n",
       "        * Biometric authentication using facial recognition, fingerprint scanning, or voice recognition.\n",
       "        * Token-based authentication using one-time passwords \u001b[1m(\u001b[0mOTPs\u001b[1m)\u001b[0m or time-based one-time passwords \u001b[1m(\u001b[0mTOTPs\u001b[1m)\u001b[0m.\n",
       "    \u001b[1;36m2\u001b[0m. **End-to-End Encryption**: We will use end-to-end encryption to protect user data, ensuring that it remains \n",
       "confidential and secure throughout the authentication process. This will include:\n",
       "        * Encrypting user data using AES-\u001b[1;36m256\u001b[0m encryption.\n",
       "        * Using secure protocols such as HTTPS and SFTP for data transfer.\n",
       "    \u001b[1;36m3\u001b[0m. **Regular Security Audits**: We will conduct regular security audits to identify and address potential \n",
       "vulnerabilities, ensuring that your user authentication system remains secure and up-to-date. This will include:\n",
       "        * Quarterly security audits to identify vulnerabilities and weaknesses.\n",
       "        * Regular software updates and patches to ensure the system remains secure.\n",
       "    \u001b[1;36m4\u001b[0m. **Clear Instructions and Guidelines**: We will provide clear instructions and guidelines for users to \n",
       "follow, ensuring that they understand the authentication process and can navigate it easily. This will include:\n",
       "        * User manuals and guides for each authentication method.\n",
       "        * Regular training sessions for users to ensure they understand the authentication process.\n",
       "\n",
       "    We believe that these components will help us deliver a high-quality user authentication system that meets your\n",
       "needs and exceeds your expectations.\n",
       "\n",
       "    If you have any questions or would like to discuss our proposal in more detail, please do not hesitate to \n",
       "contact us.\n",
       "\n",
       "    Best regards,\n",
       "    AI Team\n",
       "    \u001b[32m\"\"\u001b[0m\"\n",
       "    return \u001b[1m{\u001b[0m\u001b[32m\"email\"\u001b[0m: email\u001b[1m}\u001b[0m\n",
       "```\n",
       "\n",
       "Changes made:\n",
       "\n",
       "\u001b[1;36m1\u001b[0m. Added a more formal greeting with the client's name.\n",
       "\u001b[1;36m2\u001b[0m. Provided a more detailed and specific proposal, including the implementation of security measures.\n",
       "\u001b[1;36m3\u001b[0m. Used more formal language and a more comprehensive list of proposed tasks.\n",
       "\u001b[1;36m4\u001b[0m. Included a more detailed closing with the AI team's name.\n",
       "\u001b[1;36m5\u001b[0m. Added a sentence to express appreciation for the opportunity to work with the client.\n",
       "\u001b[1;36m6\u001b[0m. Emphasized the key components of the proposal to make it clearer and more concise.\n",
       "\u001b[1;36m7\u001b[0m. Added a sentence to invite the client to discuss the proposal in more detail.\n",
       "\u001b[1;36m8\u001b[0m. Added more specific details about the proposed tasks, such as the implementation of password authentication, \n",
       "biometric authentication, and token-based authentication.\n",
       "\u001b[1;36m9\u001b[0m. Added more specific details about the end-to-end encryption, such as the use of AES-\u001b[1;36m256\u001b[0m encryption and secure \n",
       "protocols.\n",
       "\u001b[1;36m10\u001b[0m. Added more specific details about the regular security audits, such as the frequency of audits and the types of\n",
       "updates and patches that will be applied.\n",
       "\n",
       "Note that I've assumed the `AgentState` object has the following attributes: `client_name`, `requirements`, and \n",
       "`tasks`. You may need to adjust the code to match your actual data structure.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(optimizer.node_functions['write_email'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Based on the feedback, I will improve the function to generate more specific and detailed tasks. Here is the \n",
       "improved function:\n",
       "\n",
       "```python\n",
       "def <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">generate_tasks</span><span style=\"font-weight: bold\">(</span>state: AgentState<span style=\"font-weight: bold\">)</span> -&gt; AgentState:\n",
       "    # Detailed task generation\n",
       "    tasks = <span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"1. Analyze project requirements and gather information about the project, including user needs, technical </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">constraints, and project goals.\\n\"</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"2. Design the user interface and user experience (UI/UX) of the website, including wireframes, prototypes,</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and high-fidelity designs, and ensure that the design is user-centered and accessible.\\n\"</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"3. Develop the task management features, including creating a database schema, implementing data models, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">writing backend code, and integrating with authentication systems.\\n\"</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"4. Implement data synchronization between the website and mobile app, including setting up APIs, data </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">exchange protocols, and ensuring data consistency across platforms.\\n\"</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"5. Test the website on multiple devices, including desktop, tablet, and mobile, to ensure cross-platform </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">compatibility, usability, and accessibility.\\n\"</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"6. Conduct thorough testing and quality assurance, including unit testing, integration testing, and user </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">acceptance testing, to ensure that the system meets the requirements and is free of defects.\\n\"</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"7. Deploy the system to production, including setting up monitoring and logging, ensuring high </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">availability and scalability, and providing ongoing support and maintenance.\\n\"</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"8. Analyze data sources and requirements, including identifying data sources, defining data models, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">setting up data collection and processing pipelines, and ensuring data quality and integrity.\\n\"</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"9. Implement data collection and processing, including setting up data ingestion, processing, and storage </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">systems, and ensuring data security and compliance.\\n\"</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"10. Develop a data analytics pipeline, including setting up data visualization tools, creating reports, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">implementing data-driven decision-making processes, and ensuring data governance and compliance.\\n\"</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"11. Integrate the task management system with other systems, including authentication, notification, and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">reporting systems, to ensure seamless user experience and data consistency.\\n\"</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"12. Conduct user research and gather feedback to inform design and development decisions, and ensure that </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the system meets user needs and expectations.\\n\"</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "    return <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"tasks\"</span>: tasks<span style=\"font-weight: bold\">}</span>\n",
       "```\n",
       "\n",
       "This improved function includes the following changes:\n",
       "\n",
       "* Added more specific and detailed tasks, such as designing the UI/UX, developing task management features, and \n",
       "implementing data synchronization.\n",
       "* Included tasks that are typically involved in developing a mobile app for task management, such as integrating \n",
       "with authentication systems and notification systems.\n",
       "* Added tasks that are relevant to setting up a data analytics pipeline, such as analyzing data sources and \n",
       "requirements, implementing data collection and processing, and developing a data analytics pipeline.\n",
       "* Included tasks that are relevant to testing and deployment, such as conducting thorough testing and quality \n",
       "assurance, and deploying the system to production.\n",
       "* Ensured that the tasks are more specific and relevant to the requirements of developing a website with user \n",
       "authentication and setting up a data analytics pipeline.\n",
       "\n",
       "This improved function should generate a more comprehensive and detailed list of tasks that are relevant to \n",
       "developing a website with user authentication and setting up a data analytics pipeline.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Based on the feedback, I will improve the function to generate more specific and detailed tasks. Here is the \n",
       "improved function:\n",
       "\n",
       "```python\n",
       "def \u001b[1;35mgenerate_tasks\u001b[0m\u001b[1m(\u001b[0mstate: AgentState\u001b[1m)\u001b[0m -> AgentState:\n",
       "    # Detailed task generation\n",
       "    tasks = \u001b[1m(\u001b[0m\n",
       "        \u001b[32m\"1. Analyze project requirements and gather information about the project, including user needs, technical \u001b[0m\n",
       "\u001b[32mconstraints, and project goals.\\n\"\u001b[0m\n",
       "        \u001b[32m\"2. Design the user interface and user experience \u001b[0m\u001b[32m(\u001b[0m\u001b[32mUI/UX\u001b[0m\u001b[32m)\u001b[0m\u001b[32m of the website, including wireframes, prototypes,\u001b[0m\n",
       "\u001b[32mand high-fidelity designs, and ensure that the design is user-centered and accessible.\\n\"\u001b[0m\n",
       "        \u001b[32m\"3. Develop the task management features, including creating a database schema, implementing data models, \u001b[0m\n",
       "\u001b[32mwriting backend code, and integrating with authentication systems.\\n\"\u001b[0m\n",
       "        \u001b[32m\"4. Implement data synchronization between the website and mobile app, including setting up APIs, data \u001b[0m\n",
       "\u001b[32mexchange protocols, and ensuring data consistency across platforms.\\n\"\u001b[0m\n",
       "        \u001b[32m\"5. Test the website on multiple devices, including desktop, tablet, and mobile, to ensure cross-platform \u001b[0m\n",
       "\u001b[32mcompatibility, usability, and accessibility.\\n\"\u001b[0m\n",
       "        \u001b[32m\"6. Conduct thorough testing and quality assurance, including unit testing, integration testing, and user \u001b[0m\n",
       "\u001b[32macceptance testing, to ensure that the system meets the requirements and is free of defects.\\n\"\u001b[0m\n",
       "        \u001b[32m\"7. Deploy the system to production, including setting up monitoring and logging, ensuring high \u001b[0m\n",
       "\u001b[32mavailability and scalability, and providing ongoing support and maintenance.\\n\"\u001b[0m\n",
       "        \u001b[32m\"8. Analyze data sources and requirements, including identifying data sources, defining data models, \u001b[0m\n",
       "\u001b[32msetting up data collection and processing pipelines, and ensuring data quality and integrity.\\n\"\u001b[0m\n",
       "        \u001b[32m\"9. Implement data collection and processing, including setting up data ingestion, processing, and storage \u001b[0m\n",
       "\u001b[32msystems, and ensuring data security and compliance.\\n\"\u001b[0m\n",
       "        \u001b[32m\"10. Develop a data analytics pipeline, including setting up data visualization tools, creating reports, \u001b[0m\n",
       "\u001b[32mimplementing data-driven decision-making processes, and ensuring data governance and compliance.\\n\"\u001b[0m\n",
       "        \u001b[32m\"11. Integrate the task management system with other systems, including authentication, notification, and \u001b[0m\n",
       "\u001b[32mreporting systems, to ensure seamless user experience and data consistency.\\n\"\u001b[0m\n",
       "        \u001b[32m\"12. Conduct user research and gather feedback to inform design and development decisions, and ensure that \u001b[0m\n",
       "\u001b[32mthe system meets user needs and expectations.\\n\"\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "    return \u001b[1m{\u001b[0m\u001b[32m\"tasks\"\u001b[0m: tasks\u001b[1m}\u001b[0m\n",
       "```\n",
       "\n",
       "This improved function includes the following changes:\n",
       "\n",
       "* Added more specific and detailed tasks, such as designing the UI/UX, developing task management features, and \n",
       "implementing data synchronization.\n",
       "* Included tasks that are typically involved in developing a mobile app for task management, such as integrating \n",
       "with authentication systems and notification systems.\n",
       "* Added tasks that are relevant to setting up a data analytics pipeline, such as analyzing data sources and \n",
       "requirements, implementing data collection and processing, and developing a data analytics pipeline.\n",
       "* Included tasks that are relevant to testing and deployment, such as conducting thorough testing and quality \n",
       "assurance, and deploying the system to production.\n",
       "* Ensured that the tasks are more specific and relevant to the requirements of developing a website with user \n",
       "authentication and setting up a data analytics pipeline.\n",
       "\n",
       "This improved function should generate a more comprehensive and detailed list of tasks that are relevant to \n",
       "developing a website with user authentication and setting up a data analytics pipeline.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(optimizer.node_functions['generate_tasks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "    Dear Client,\n",
       "\n",
       "    Based on your requirements: Analyze customer data and provide recommendations\n",
       "\n",
       "    We propose the following tasks:\n",
       "    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. Analyze requirements\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. Develop solution\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. Test and deploy\n",
       "\n",
       "    Best regards,\n",
       "    AI Team\n",
       "    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "    Dear Client,\n",
       "\n",
       "    Based on your requirements: Analyze customer data and provide recommendations\n",
       "\n",
       "    We propose the following tasks:\n",
       "    \u001b[1;36m1\u001b[0m. Analyze requirements\n",
       "\u001b[1;36m2\u001b[0m. Develop solution\n",
       "\u001b[1;36m3\u001b[0m. Test and deploy\n",
       "\n",
       "    Best regards,\n",
       "    AI Team\n",
       "    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_measure_model_retraining_speed() -> ChatPromptTemplate:\n",
    "    examples = [\n",
    "        {\n",
    "            \"input\": textwrap.dedent(\"\"\"\n",
    "            [HERE GOES THE INPUT 1]\n",
    "            \"\"\"),\n",
    "            \"output\": textwrap.dedent(\"\"\"\n",
    "            [HERE GOES THE OUTPUT 1]            \n",
    "            \"\"\")\n",
    "        },\n",
    "        {\n",
    "            \"input\": textwrap.dedent(\"\"\"\n",
    "             [HERE GOES THE INPUT 2]\n",
    "            \"\"\"),\n",
    "            \"output\": textwrap.dedent(\"\"\"\n",
    "              [HERE GOES THE OUTPUT 2] \n",
    "            \"\"\")\n",
    "        }\"\n",
    "    ]\n",
    "    \n",
    "    example_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"human\", \"{input}\"),\n",
    "            (\"ai\", \"{output}\"),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "        example_prompt=example_prompt,\n",
    "        examples=examples,\n",
    "    )\n",
    "\n",
    "    system_prompt = textwrap.dedent(\"\"\"\n",
    "    [HERE GOES THE SYSTEM PROMPT]\n",
    "    \"\"\")\n",
    "\n",
    "    final_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_prompt),\n",
    "            few_shot_prompt,\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "    return final_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Dear Client,\n",
      "\n",
      "    Based on your requirements: Analyze customer data and provide recommendations\n",
      "\n",
      "    We propose the following tasks:\n",
      "    1. Analyze requirements\n",
      "2. Develop solution\n",
      "3. Test and deploy\n",
      "\n",
      "    Best regards,\n",
      "    AI Team\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    requirements: str\n",
    "    email: str\n",
    "\n",
    "def write_email(state: AgentState) -> AgentState:\n",
    "    # Hardcoded tasks\n",
    "    tasks = \"1. Analyze requirements\\n2. Develop solution\\n3. Test and deploy\"\n",
    "    \n",
    "    # Simplified email writing\n",
    "    email = f\"\"\"\n",
    "    Dear Client,\n",
    "\n",
    "    Based on your requirements: {state['requirements']}\n",
    "\n",
    "    We propose the following tasks:\n",
    "    {tasks}\n",
    "\n",
    "    Best regards,\n",
    "    AI Team\n",
    "    \"\"\"\n",
    "    return {\"email\": email}\n",
    "\n",
    "# Initialize the graph\n",
    "graph = StateGraph(AgentState)\n",
    "graph.add_node(\"write_email\", write_email)\n",
    "graph.add_edge(\"write_email\", END)\n",
    "graph.set_entry_point(\"write_email\")\n",
    "\n",
    "workflow = graph.compile()\n",
    "\n",
    "# Function to run the workflow\n",
    "def generate_email(requirements: str) -> str:\n",
    "    result = workflow.invoke({\"requirements\": requirements})\n",
    "    return result[\"email\"]\n",
    "\n",
    "requirements = \"Analyze customer data and provide recommendations\"\n",
    "email = generate_email(requirements)\n",
    "print(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.write_email(state: __main__.AgentState) -> __main__.AgentState>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.nodes['write_email'].func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'StateGraph' object has no attribute 'func'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m inspect\u001b[38;5;241m.\u001b[39mgetsource(\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'StateGraph' object has no attribute 'func'"
     ]
    }
   ],
   "source": [
    "inspect.getsource(graph.func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def write_email(state: AgentState) -> AgentState:\n",
      "    # Hardcoded tasks\n",
      "    tasks = \"1. Analyze requirements\\n2. Develop solution\\n3. Test and deploy\"\n",
      "    \n",
      "    # Simplified email writing\n",
      "    email = f\"\"\"\n",
      "    Dear Client,\n",
      "\n",
      "    Based on your requirements: {state['requirements']}\n",
      "\n",
      "    We propose the following tasks:\n",
      "    {tasks}\n",
      "\n",
      "    Best regards,\n",
      "    AI Team\n",
      "    \"\"\"\n",
      "    return {\"email\": email}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for node_name, node_func in graph.nodes.items():\n",
    "    print(inspect.getsource(node_func.func))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect.getsource(func.func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('write_email', write_email(recurse=True))])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.nodes.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">input : Develop a mobile app for task management\n",
       "</pre>\n"
      ],
      "text/plain": [
       "input : Develop a mobile app for task management\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">output : \n",
       "        Dear Client,\n",
       "\n",
       "        Based on your requirements: Develop a mobile app for task management\n",
       "\n",
       "        We propose the following tasks:\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. Analyze user requirements and define app features\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. Design intuitive UI/UX for task management\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. Develop core functionality <span style=\"font-weight: bold\">(</span>task creation, editing, deletion<span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>. Implement data synchronization and cloud storage\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>. Conduct thorough testing on multiple devices\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>. Deploy to app stores and gather user feedback\n",
       "\n",
       "        Best regards,\n",
       "        AI Team\n",
       "        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "output : \n",
       "        Dear Client,\n",
       "\n",
       "        Based on your requirements: Develop a mobile app for task management\n",
       "\n",
       "        We propose the following tasks:\n",
       "        \u001b[1;36m1\u001b[0m. Analyze user requirements and define app features\n",
       "        \u001b[1;36m2\u001b[0m. Design intuitive UI/UX for task management\n",
       "        \u001b[1;36m3\u001b[0m. Develop core functionality \u001b[1m(\u001b[0mtask creation, editing, deletion\u001b[1m)\u001b[0m\n",
       "        \u001b[1;36m4\u001b[0m. Implement data synchronization and cloud storage\n",
       "        \u001b[1;36m5\u001b[0m. Conduct thorough testing on multiple devices\n",
       "        \u001b[1;36m6\u001b[0m. Deploy to app stores and gather user feedback\n",
       "\n",
       "        Best regards,\n",
       "        AI Team\n",
       "        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">input : Create an e-commerce website with payment integration\n",
       "</pre>\n"
      ],
      "text/plain": [
       "input : Create an e-commerce website with payment integration\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">output : \n",
       "        Dear Client,\n",
       "\n",
       "        Based on your requirements: Create an e-commerce website with payment integration\n",
       "\n",
       "        We propose the following tasks:\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. Analyze business requirements and select appropriate e-commerce platform\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. Design responsive and user-friendly website layout\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. Set up product catalog and inventory management system\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>. Implement secure payment gateway integration\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>. Develop order processing and shipment tracking features\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>. Conduct thorough security and performance testing\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>. Launch website and provide post-launch support\n",
       "\n",
       "        Best regards,\n",
       "        AI Team\n",
       "        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "output : \n",
       "        Dear Client,\n",
       "\n",
       "        Based on your requirements: Create an e-commerce website with payment integration\n",
       "\n",
       "        We propose the following tasks:\n",
       "        \u001b[1;36m1\u001b[0m. Analyze business requirements and select appropriate e-commerce platform\n",
       "        \u001b[1;36m2\u001b[0m. Design responsive and user-friendly website layout\n",
       "        \u001b[1;36m3\u001b[0m. Set up product catalog and inventory management system\n",
       "        \u001b[1;36m4\u001b[0m. Implement secure payment gateway integration\n",
       "        \u001b[1;36m5\u001b[0m. Develop order processing and shipment tracking features\n",
       "        \u001b[1;36m6\u001b[0m. Conduct thorough security and performance testing\n",
       "        \u001b[1;36m7\u001b[0m. Launch website and provide post-launch support\n",
       "\n",
       "        Best regards,\n",
       "        AI Team\n",
       "        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(ground_truth)\n",
    "\n",
    "#Create a recursive print function for the list of dictionaries\n",
    "def print_dict_list(dict_list):\n",
    "    for i in dict_list:\n",
    "        for key, value in i.items():\n",
    "            print(key, \":\", value)\n",
    "        # print(\"\\n\")\n",
    "\n",
    "print_dict_list(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Iteration <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Iteration \u001b[1;36m1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Processing example <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Processing example \u001b[1;36m1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Error processing example <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'str'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'update'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Error processing example \u001b[1;36m1\u001b[0m: \u001b[32m'str'\u001b[0m object has no attribute \u001b[32m'update'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Processing example <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Processing example \u001b[1;36m2\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Error processing example <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'str'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'update'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Error processing example \u001b[1;36m2\u001b[0m: \u001b[32m'str'\u001b[0m object has no attribute \u001b[32m'update'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Processing example <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Processing example \u001b[1;36m3\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Error processing example <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'str'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'update'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Error processing example \u001b[1;36m3\u001b[0m: \u001b[32m'str'\u001b[0m object has no attribute \u001b[32m'update'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Updated write_email\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Updated write_email\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Iteration <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Iteration \u001b[1;36m2\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Processing example <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Processing example \u001b[1;36m1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Error processing example <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: unterminated string literal <span style=\"font-weight: bold\">(</span>detected at line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">61</span><span style=\"font-weight: bold\">)</span> <span style=\"font-weight: bold\">(&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">string</span><span style=\"font-weight: bold\">&gt;</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">61</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Error processing example \u001b[1;36m1\u001b[0m: unterminated string literal \u001b[1m(\u001b[0mdetected at line \u001b[1;36m61\u001b[0m\u001b[1m)\u001b[0m \u001b[1m(\u001b[0m\u001b[1m<\u001b[0m\u001b[1;95mstring\u001b[0m\u001b[1m>\u001b[0m, line \u001b[1;36m61\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Processing example <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Processing example \u001b[1;36m2\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Error processing example <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: unterminated string literal <span style=\"font-weight: bold\">(</span>detected at line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">61</span><span style=\"font-weight: bold\">)</span> <span style=\"font-weight: bold\">(&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">string</span><span style=\"font-weight: bold\">&gt;</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">61</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Error processing example \u001b[1;36m2\u001b[0m: unterminated string literal \u001b[1m(\u001b[0mdetected at line \u001b[1;36m61\u001b[0m\u001b[1m)\u001b[0m \u001b[1m(\u001b[0m\u001b[1m<\u001b[0m\u001b[1;95mstring\u001b[0m\u001b[1m>\u001b[0m, line \u001b[1;36m61\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Processing example <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Processing example \u001b[1;36m3\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Error processing example <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: unterminated string literal <span style=\"font-weight: bold\">(</span>detected at line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">61</span><span style=\"font-weight: bold\">)</span> <span style=\"font-weight: bold\">(&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">string</span><span style=\"font-weight: bold\">&gt;</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">61</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Error processing example \u001b[1;36m3\u001b[0m: unterminated string literal \u001b[1m(\u001b[0mdetected at line \u001b[1;36m61\u001b[0m\u001b[1m)\u001b[0m \u001b[1m(\u001b[0m\u001b[1m<\u001b[0m\u001b[1;95mstring\u001b[0m\u001b[1m>\u001b[0m, line \u001b[1;36m61\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Updated write_email\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Updated write_email\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Iteration <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Iteration \u001b[1;36m3\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Processing example <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Processing example \u001b[1;36m1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Error processing example <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: unterminated string literal <span style=\"font-weight: bold\">(</span>detected at line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">71</span><span style=\"font-weight: bold\">)</span> <span style=\"font-weight: bold\">(&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">string</span><span style=\"font-weight: bold\">&gt;</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">71</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Error processing example \u001b[1;36m1\u001b[0m: unterminated string literal \u001b[1m(\u001b[0mdetected at line \u001b[1;36m71\u001b[0m\u001b[1m)\u001b[0m \u001b[1m(\u001b[0m\u001b[1m<\u001b[0m\u001b[1;95mstring\u001b[0m\u001b[1m>\u001b[0m, line \u001b[1;36m71\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Processing example <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Processing example \u001b[1;36m2\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Error processing example <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: unterminated string literal <span style=\"font-weight: bold\">(</span>detected at line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">71</span><span style=\"font-weight: bold\">)</span> <span style=\"font-weight: bold\">(&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">string</span><span style=\"font-weight: bold\">&gt;</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">71</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Error processing example \u001b[1;36m2\u001b[0m: unterminated string literal \u001b[1m(\u001b[0mdetected at line \u001b[1;36m71\u001b[0m\u001b[1m)\u001b[0m \u001b[1m(\u001b[0m\u001b[1m<\u001b[0m\u001b[1;95mstring\u001b[0m\u001b[1m>\u001b[0m, line \u001b[1;36m71\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Processing example <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Processing example \u001b[1;36m3\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Error processing example <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: unterminated string literal <span style=\"font-weight: bold\">(</span>detected at line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">71</span><span style=\"font-weight: bold\">)</span> <span style=\"font-weight: bold\">(&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">string</span><span style=\"font-weight: bold\">&gt;</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">71</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Error processing example \u001b[1;36m3\u001b[0m: unterminated string literal \u001b[1m(\u001b[0mdetected at line \u001b[1;36m71\u001b[0m\u001b[1m)\u001b[0m \u001b[1m(\u001b[0m\u001b[1m<\u001b[0m\u001b[1;95mstring\u001b[0m\u001b[1m>\u001b[0m, line \u001b[1;36m71\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Updated write_email\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Updated write_email\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'invoke'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 197\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# Test the optimized graph\u001b[39;00m\n\u001b[1;32m    196\u001b[0m test_input \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequirements\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDesign a customer loyalty program for a retail chain\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m--> 197\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43moptimized_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m(test_input)\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'invoke'"
     ]
    }
   ],
   "source": [
    "from rich import print\n",
    "import inspect\n",
    "from typing import List, Dict, Any\n",
    "from langgraph.graph import StateGraph\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "class GraphAgentOptimizer:\n",
    "    def __init__(self, original_graph: StateGraph, ground_truth: List[Dict[str, Any]], llm):\n",
    "        self.original_graph = original_graph\n",
    "        self.ground_truth = ground_truth\n",
    "        self.llm = llm\n",
    "        self.node_functions = {}\n",
    "        self.node_performances = {}\n",
    "\n",
    "    def load_graph(self):\n",
    "        for node_name, node_func in self.original_graph.nodes.items():\n",
    "            self.node_functions[node_name] = self.extract_function_source(node_func)\n",
    "            self.node_performances[node_name] = {'score': 0, 'feedback': ''}\n",
    "\n",
    "    def extract_function_source(self, func):\n",
    "        if hasattr(func, 'func'):  # For RunnableCallable objects\n",
    "            return inspect.getsource(func.func)\n",
    "        elif callable(func):\n",
    "            return inspect.getsource(func)\n",
    "        else:\n",
    "            return str(func)  # Fallback for other types\n",
    "\n",
    "    def optimize(self, num_iterations: int):\n",
    "        for iteration in range(num_iterations):\n",
    "            print(f\"Iteration {iteration + 1}\")\n",
    "            for i, example in enumerate(self.ground_truth):\n",
    "                print(f\"  Processing example {i + 1}\")\n",
    "                try:\n",
    "                    output = self.forward_pass(example['input'])\n",
    "                    self.evaluate_and_update(output, example['output'])\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing example {i + 1}: {str(e)}\")\n",
    "            self.update_node_functions()\n",
    "\n",
    "    def forward_pass(self, input_data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        state = input_data#.copy()\n",
    "        for node_name in self.original_graph.nodes:\n",
    "            node_func = self.get_node_function(node_name)\n",
    "            state.update(node_func(state))\n",
    "        return state\n",
    "\n",
    "    def evaluate_and_update(self, generated_output: Dict[str, Any], ground_truth_output: Dict[str, Any]):\n",
    "        prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        Compare the generated output with the ground truth output.\n",
    "        Provide a score from 0 to 1 for each node in the graph,\n",
    "        where 1 is perfect and 0 is completely wrong.\n",
    "        Also provide a brief explanation for each score.\n",
    "\n",
    "        Generated output:\n",
    "        {generated_output}\n",
    "\n",
    "        Ground truth output:\n",
    "        {ground_truth_output}\n",
    "\n",
    "        Response format:\n",
    "        [node_name] score: [score]\n",
    "        [node_name] feedback: [feedback]\n",
    "        (Repeat for each node)\n",
    "        \"\"\")\n",
    "        chain = prompt | self.llm\n",
    "        response = chain.invoke({\n",
    "            \"generated_output\": str(generated_output),\n",
    "            \"ground_truth_output\": str(ground_truth_output)\n",
    "        })\n",
    "\n",
    "        print(\"Raw LLM response:\")\n",
    "        print(response.content)\n",
    "        \n",
    "        lines = response.content.split('\\n')\n",
    "        for node_name in self.node_functions.keys():\n",
    "            score_line = next((line for line in lines if f\"{node_name} score:\" in line), None)\n",
    "            feedback_line = next((line for line in lines if f\"{node_name} feedback:\" in line), None)\n",
    "            \n",
    "            if score_line and feedback_line:\n",
    "                try:\n",
    "                    score = float(score_line.split(':')[1].strip())\n",
    "                except ValueError:\n",
    "                    print(f\"Warning: Could not parse score for {node_name}. Using default score of 0.5\")\n",
    "                    score = 0.5\n",
    "                \n",
    "                feedback = feedback_line.split(':', 1)[1].strip() if ':' in feedback_line else ''\n",
    "                \n",
    "                self.node_performances[node_name]['score'] = (self.node_performances[node_name]['score'] + score) / 2\n",
    "                self.node_performances[node_name]['feedback'] += feedback + '\\n'\n",
    "            else:\n",
    "                print(f\"Warning: Could not find score or feedback for {node_name}\")\n",
    "\n",
    "    def update_node_functions(self):\n",
    "        for node_name, performance in self.node_performances.items():\n",
    "            if performance['score'] < 0.8:\n",
    "                prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "                Improve the following function based on the feedback:\n",
    "\n",
    "                Original function:\n",
    "                {original_function}\n",
    "\n",
    "                Performance score: {score}\n",
    "                Feedback: {feedback}\n",
    "\n",
    "                The improved function should follow this template:\n",
    "\n",
    "                        def {{node_name}}(state: AgentState) -> AgentState:\n",
    "                            def updated_node() -> ChatPromptTemplate:\n",
    "                                examples = [\n",
    "                                    {{\n",
    "                                        \"input\": textwrap.dedent('''\n",
    "                                        [HERE GOES THE INPUT 1]\n",
    "                                        '''),\n",
    "                                        \"output\": textwrap.dedent('''\n",
    "                                        [HERE GOES THE OUTPUT 1]            \n",
    "                                        ''')\n",
    "                                    }},\n",
    "                                    {{\n",
    "                                        \"input\": textwrap.dedent('''\n",
    "                                        [HERE GOES THE INPUT 2]\n",
    "                                        '''),\n",
    "                                        \"output\": textwrap.dedent('''\n",
    "                                        [HERE GOES THE OUTPUT 2] \n",
    "                                        ''')\n",
    "                                    }}\n",
    "                                ]\n",
    "                                \n",
    "                                example_prompt = ChatPromptTemplate.from_messages(\n",
    "                                    [\n",
    "                                        (\"human\", \"{{input}}\"),\n",
    "                                        (\"ai\", \"{{output}}\"),\n",
    "                                    ]\n",
    "                                )\n",
    "                                \n",
    "                                few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "                                    example_prompt=example_prompt,\n",
    "                                    examples=examples,\n",
    "                                )\n",
    "                                system_prompt = textwrap.dedent('''\n",
    "                                [HERE GOES THE SYSTEM PROMPT]\n",
    "                                ''')\n",
    "                                final_prompt = ChatPromptTemplate.from_messages(\n",
    "                                    [\n",
    "                                        (\"system\", system_prompt),\n",
    "                                        few_shot_prompt,\n",
    "                                        (\"human\", \"{{input}}\"),\n",
    "                                    ]\n",
    "                                )\n",
    "                                return final_prompt\n",
    "                                                          \n",
    "                \"\"\")\n",
    "                chain = prompt | self.llm\n",
    "                response = chain.invoke({\n",
    "                    \"original_function\": self.node_functions[node_name],\n",
    "                    \"score\": performance['score'],\n",
    "                    \"feedback\": performance['feedback']\n",
    "                })\n",
    "                self.node_functions[node_name] = response.content\n",
    "                print(f\"Updated {node_name}\")\n",
    "\n",
    "    def get_node_function(self, node_name: str) -> callable:\n",
    "        function_code = self.node_functions[node_name]\n",
    "        exec(function_code, globals())\n",
    "        return eval(node_name)\n",
    "\n",
    "    def export_optimized_graph(self) -> StateGraph:\n",
    "        optimized_graph = StateGraph(self.original_graph.state_type)\n",
    "        for node_name, node_func in self.node_functions.items():\n",
    "            optimized_graph.add_node(node_name, self.get_node_function(node_name))\n",
    "        \n",
    "        for edge in self.original_graph.edges:\n",
    "            optimized_graph.add_edge(edge.start, edge.end)\n",
    "        \n",
    "        for conditional_edge in self.original_graph.conditional_edges:\n",
    "            optimized_graph.add_conditional_edges(\n",
    "                conditional_edge.start,\n",
    "                conditional_edge.condition,\n",
    "                conditional_edge.edge_map\n",
    "            )\n",
    "        \n",
    "        optimized_graph.set_entry_point(self.original_graph.entry_point)\n",
    "        \n",
    "        return optimized_graph.compile()\n",
    "\n",
    "# Usage\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm_name = \"llama-3.1-8b-instant\"\n",
    "llm = ChatGroq(cache=False, temperature=0.0, model_name=llm_name)\n",
    "optimizer = GraphAgentOptimizer(graph, ground_truth, llm)\n",
    "optimizer.load_graph()\n",
    "optimized_graph = optimizer.optimize(num_iterations=3)\n",
    "\n",
    "# Test the optimized graph\n",
    "test_input = {\"requirements\": \"Design a customer loyalty program for a retail chain\"}\n",
    "result = optimized_graph.invoke(test_input)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(optimizer.node_functions['write_email'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Loading graph<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Loading graph\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Graph loaded successfully.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Graph loaded successfully.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Iteration <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Iteration \u001b[1;36m1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Processing example <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Processing example \u001b[1;36m1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Starting forward pass with input: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'requirements'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Develop a website with user authentication'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Starting forward pass with input: \u001b[1m{\u001b[0m\u001b[32m'requirements'\u001b[0m: \u001b[32m'Develop a website with user authentication'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Executing function code for write_email:\n",
       "def <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">write_email</span><span style=\"font-weight: bold\">(</span>state: AgentState<span style=\"font-weight: bold\">)</span> -&gt; AgentState:\n",
       "    # Hardcoded tasks\n",
       "    tasks = <span style=\"color: #008000; text-decoration-color: #008000\">\"1. Analyze requirements\\n2. Develop solution\\n3. Test and deploy\"</span>\n",
       "    \n",
       "    # Simplified email writing\n",
       "    email = f\"<span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>\n",
       "    Dear Client,\n",
       "\n",
       "    Based on your requirements: <span style=\"font-weight: bold\">{</span>state<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'requirements'</span><span style=\"font-weight: bold\">]}</span>\n",
       "\n",
       "    We propose the following tasks:\n",
       "    <span style=\"font-weight: bold\">{</span>tasks<span style=\"font-weight: bold\">}</span>\n",
       "\n",
       "    Best regards,\n",
       "    AI Team\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>\"\n",
       "    return <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"email\"</span>: email<span style=\"font-weight: bold\">}</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Executing function code for write_email:\n",
       "def \u001b[1;35mwrite_email\u001b[0m\u001b[1m(\u001b[0mstate: AgentState\u001b[1m)\u001b[0m -> AgentState:\n",
       "    # Hardcoded tasks\n",
       "    tasks = \u001b[32m\"1. Analyze requirements\\n2. Develop solution\\n3. Test and deploy\"\u001b[0m\n",
       "    \n",
       "    # Simplified email writing\n",
       "    email = f\"\u001b[32m\"\"\u001b[0m\n",
       "    Dear Client,\n",
       "\n",
       "    Based on your requirements: \u001b[1m{\u001b[0mstate\u001b[1m[\u001b[0m\u001b[32m'requirements'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m\n",
       "\n",
       "    We propose the following tasks:\n",
       "    \u001b[1m{\u001b[0mtasks\u001b[1m}\u001b[0m\n",
       "\n",
       "    Best regards,\n",
       "    AI Team\n",
       "    \u001b[32m\"\"\u001b[0m\"\n",
       "    return \u001b[1m{\u001b[0m\u001b[32m\"email\"\u001b[0m: email\u001b[1m}\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">State after forward pass: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'requirements'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Develop a website with user authentication'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'email'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'\\n    Dear </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Client,\\n\\n    Based on your requirements: Develop a website with user authentication\\n\\n    We propose the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">following tasks:\\n    1. Analyze requirements\\n2. Develop solution\\n3. Test and deploy\\n\\n    Best regards,\\n    AI</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Team\\n    '</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "State after forward pass: \u001b[1m{\u001b[0m\u001b[32m'requirements'\u001b[0m: \u001b[32m'Develop a website with user authentication'\u001b[0m, \u001b[32m'email'\u001b[0m: \u001b[32m'\\n    Dear \u001b[0m\n",
       "\u001b[32mClient,\\n\\n    Based on your requirements: Develop a website with user authentication\\n\\n    We propose the \u001b[0m\n",
       "\u001b[32mfollowing tasks:\\n    1. Analyze requirements\\n2. Develop solution\\n3. Test and deploy\\n\\n    Best regards,\\n    AI\u001b[0m\n",
       "\u001b[32mTeam\\n    '\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Output for example <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'requirements'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Develop a website with user authentication'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'email'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'\\n    Dear </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Client,\\n\\n    Based on your requirements: Develop a website with user authentication\\n\\n    We propose the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">following tasks:\\n    1. Analyze requirements\\n2. Develop solution\\n3. Test and deploy\\n\\n    Best regards,\\n    AI</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Team\\n    '</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Output for example \u001b[1;36m1\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'requirements'\u001b[0m: \u001b[32m'Develop a website with user authentication'\u001b[0m, \u001b[32m'email'\u001b[0m: \u001b[32m'\\n    Dear \u001b[0m\n",
       "\u001b[32mClient,\\n\\n    Based on your requirements: Develop a website with user authentication\\n\\n    We propose the \u001b[0m\n",
       "\u001b[32mfollowing tasks:\\n    1. Analyze requirements\\n2. Develop solution\\n3. Test and deploy\\n\\n    Best regards,\\n    AI\u001b[0m\n",
       "\u001b[32mTeam\\n    '\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Raw LLM response:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Raw LLM response:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Here is the comparison of the generated output with the ground truth output:\n",
       "\n",
       "**Requirements** score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span>\n",
       "**Requirements** feedback: The generated output is partially correct, but it lacks the specific details mentioned \n",
       "in the ground truth output, such as <span style=\"color: #008000; text-decoration-color: #008000\">\"Design user authentication system\"</span> and <span style=\"color: #008000; text-decoration-color: #008000\">\"Implement security measures\"</span>.\n",
       "\n",
       "**Email** score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8</span>\n",
       "**Email** feedback: The generated output is mostly correct, but it lacks the specific tasks mentioned in the ground\n",
       "truth output, such as <span style=\"color: #008000; text-decoration-color: #008000\">\"Implement security measures\"</span> and <span style=\"color: #008000; text-decoration-color: #008000\">\"Test and deploy website\"</span>. The tone and structure of the \n",
       "email are also slightly different.\n",
       "\n",
       "Note that the scores are subjective and based on the specific requirements of the task. The scores can be adjusted \n",
       "based on the specific criteria used to evaluate the output.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Here is the comparison of the generated output with the ground truth output:\n",
       "\n",
       "**Requirements** score: \u001b[1;36m0.5\u001b[0m\n",
       "**Requirements** feedback: The generated output is partially correct, but it lacks the specific details mentioned \n",
       "in the ground truth output, such as \u001b[32m\"Design user authentication system\"\u001b[0m and \u001b[32m\"Implement security measures\"\u001b[0m.\n",
       "\n",
       "**Email** score: \u001b[1;36m0.8\u001b[0m\n",
       "**Email** feedback: The generated output is mostly correct, but it lacks the specific tasks mentioned in the ground\n",
       "truth output, such as \u001b[32m\"Implement security measures\"\u001b[0m and \u001b[32m\"Test and deploy website\"\u001b[0m. The tone and structure of the \n",
       "email are also slightly different.\n",
       "\n",
       "Note that the scores are subjective and based on the specific requirements of the task. The scores can be adjusted \n",
       "based on the specific criteria used to evaluate the output.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Warning: Could not find score or feedback for write_email\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Warning: Could not find score or feedback for write_email\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Processing example <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Processing example \u001b[1;36m2\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Starting forward pass with input: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'requirements'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Create a mobile app for task management'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Starting forward pass with input: \u001b[1m{\u001b[0m\u001b[32m'requirements'\u001b[0m: \u001b[32m'Create a mobile app for task management'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Executing function code for write_email:\n",
       "def <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">write_email</span><span style=\"font-weight: bold\">(</span>state: AgentState<span style=\"font-weight: bold\">)</span> -&gt; AgentState:\n",
       "    # Hardcoded tasks\n",
       "    tasks = <span style=\"color: #008000; text-decoration-color: #008000\">\"1. Analyze requirements\\n2. Develop solution\\n3. Test and deploy\"</span>\n",
       "    \n",
       "    # Simplified email writing\n",
       "    email = f\"<span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>\n",
       "    Dear Client,\n",
       "\n",
       "    Based on your requirements: <span style=\"font-weight: bold\">{</span>state<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'requirements'</span><span style=\"font-weight: bold\">]}</span>\n",
       "\n",
       "    We propose the following tasks:\n",
       "    <span style=\"font-weight: bold\">{</span>tasks<span style=\"font-weight: bold\">}</span>\n",
       "\n",
       "    Best regards,\n",
       "    AI Team\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>\"\n",
       "    return <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"email\"</span>: email<span style=\"font-weight: bold\">}</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Executing function code for write_email:\n",
       "def \u001b[1;35mwrite_email\u001b[0m\u001b[1m(\u001b[0mstate: AgentState\u001b[1m)\u001b[0m -> AgentState:\n",
       "    # Hardcoded tasks\n",
       "    tasks = \u001b[32m\"1. Analyze requirements\\n2. Develop solution\\n3. Test and deploy\"\u001b[0m\n",
       "    \n",
       "    # Simplified email writing\n",
       "    email = f\"\u001b[32m\"\"\u001b[0m\n",
       "    Dear Client,\n",
       "\n",
       "    Based on your requirements: \u001b[1m{\u001b[0mstate\u001b[1m[\u001b[0m\u001b[32m'requirements'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m\n",
       "\n",
       "    We propose the following tasks:\n",
       "    \u001b[1m{\u001b[0mtasks\u001b[1m}\u001b[0m\n",
       "\n",
       "    Best regards,\n",
       "    AI Team\n",
       "    \u001b[32m\"\"\u001b[0m\"\n",
       "    return \u001b[1m{\u001b[0m\u001b[32m\"email\"\u001b[0m: email\u001b[1m}\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">State after forward pass: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'requirements'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Create a mobile app for task management'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'email'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'\\n    Dear </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Client,\\n\\n    Based on your requirements: Create a mobile app for task management\\n\\n    We propose the following </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks:\\n    1. Analyze requirements\\n2. Develop solution\\n3. Test and deploy\\n\\n    Best regards,\\n    AI Team\\n   </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "State after forward pass: \u001b[1m{\u001b[0m\u001b[32m'requirements'\u001b[0m: \u001b[32m'Create a mobile app for task management'\u001b[0m, \u001b[32m'email'\u001b[0m: \u001b[32m'\\n    Dear \u001b[0m\n",
       "\u001b[32mClient,\\n\\n    Based on your requirements: Create a mobile app for task management\\n\\n    We propose the following \u001b[0m\n",
       "\u001b[32mtasks:\\n    1. Analyze requirements\\n2. Develop solution\\n3. Test and deploy\\n\\n    Best regards,\\n    AI Team\\n   \u001b[0m\n",
       "\u001b[32m'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Output for example <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'requirements'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Create a mobile app for task management'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'email'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'\\n    Dear Client,\\n\\n </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Based on your requirements: Create a mobile app for task management\\n\\n    We propose the following tasks:\\n    1. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Analyze requirements\\n2. Develop solution\\n3. Test and deploy\\n\\n    Best regards,\\n    AI Team\\n    '</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Output for example \u001b[1;36m2\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'requirements'\u001b[0m: \u001b[32m'Create a mobile app for task management'\u001b[0m, \u001b[32m'email'\u001b[0m: \u001b[32m'\\n    Dear Client,\\n\\n \u001b[0m\n",
       "\u001b[32mBased on your requirements: Create a mobile app for task management\\n\\n    We propose the following tasks:\\n    1. \u001b[0m\n",
       "\u001b[32mAnalyze requirements\\n2. Develop solution\\n3. Test and deploy\\n\\n    Best regards,\\n    AI Team\\n    '\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Raw LLM response:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Raw LLM response:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Here is the comparison of the generated output with the ground truth output:\n",
       "\n",
       "**Requirements** score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6</span>\n",
       "**Requirements** feedback: The generated output is close, but it mentions <span style=\"color: #008000; text-decoration-color: #008000\">\"Analyze requirements\"</span> which is not \n",
       "present in the ground truth output. The ground truth output also mentions <span style=\"color: #008000; text-decoration-color: #008000\">\"Design app UI/UX\"</span> which is not present \n",
       "in the generated output.\n",
       "\n",
       "**Email** score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8</span>\n",
       "**Email** feedback: The generated output is mostly correct, but it lacks the specific tasks mentioned in the ground\n",
       "truth output <span style=\"font-weight: bold\">(</span>Design app UI/UX, Implement data synchronization, Test on multiple devices, Deploy to app stores<span style=\"font-weight: bold\">)</span>. \n",
       "The generated output also uses a more generic phrase <span style=\"color: #008000; text-decoration-color: #008000\">\"We propose the following tasks\"</span> instead of the more specific \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"We propose the following tasks:\"</span>.\n",
       "\n",
       "**Email** score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9</span>\n",
       "**Email** feedback: The generated output is mostly correct, but it lacks the specific tasks mentioned in the ground\n",
       "truth output <span style=\"font-weight: bold\">(</span>Design app UI/UX, Implement data synchronization, Test on multiple devices, Deploy to app stores<span style=\"font-weight: bold\">)</span>. \n",
       "The generated output also uses a more generic phrase <span style=\"color: #008000; text-decoration-color: #008000\">\"We propose the following tasks\"</span> instead of the more specific \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"We propose the following tasks:\"</span>.\n",
       "\n",
       "Note: The score for the <span style=\"color: #008000; text-decoration-color: #008000\">\"Email\"</span> node is high because the generated output is mostly correct in terms of structure \n",
       "and content, but it lacks some specific details.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Here is the comparison of the generated output with the ground truth output:\n",
       "\n",
       "**Requirements** score: \u001b[1;36m0.6\u001b[0m\n",
       "**Requirements** feedback: The generated output is close, but it mentions \u001b[32m\"Analyze requirements\"\u001b[0m which is not \n",
       "present in the ground truth output. The ground truth output also mentions \u001b[32m\"Design app UI/UX\"\u001b[0m which is not present \n",
       "in the generated output.\n",
       "\n",
       "**Email** score: \u001b[1;36m0.8\u001b[0m\n",
       "**Email** feedback: The generated output is mostly correct, but it lacks the specific tasks mentioned in the ground\n",
       "truth output \u001b[1m(\u001b[0mDesign app UI/UX, Implement data synchronization, Test on multiple devices, Deploy to app stores\u001b[1m)\u001b[0m. \n",
       "The generated output also uses a more generic phrase \u001b[32m\"We propose the following tasks\"\u001b[0m instead of the more specific \n",
       "\u001b[32m\"We propose the following tasks:\"\u001b[0m.\n",
       "\n",
       "**Email** score: \u001b[1;36m0.9\u001b[0m\n",
       "**Email** feedback: The generated output is mostly correct, but it lacks the specific tasks mentioned in the ground\n",
       "truth output \u001b[1m(\u001b[0mDesign app UI/UX, Implement data synchronization, Test on multiple devices, Deploy to app stores\u001b[1m)\u001b[0m. \n",
       "The generated output also uses a more generic phrase \u001b[32m\"We propose the following tasks\"\u001b[0m instead of the more specific \n",
       "\u001b[32m\"We propose the following tasks:\"\u001b[0m.\n",
       "\n",
       "Note: The score for the \u001b[32m\"Email\"\u001b[0m node is high because the generated output is mostly correct in terms of structure \n",
       "and content, but it lacks some specific details.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Warning: Could not find score or feedback for write_email\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Warning: Could not find score or feedback for write_email\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Processing example <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Processing example \u001b[1;36m3\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Starting forward pass with input: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'requirements'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Set up a data analytics pipeline'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Starting forward pass with input: \u001b[1m{\u001b[0m\u001b[32m'requirements'\u001b[0m: \u001b[32m'Set up a data analytics pipeline'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Executing function code for write_email:\n",
       "def <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">write_email</span><span style=\"font-weight: bold\">(</span>state: AgentState<span style=\"font-weight: bold\">)</span> -&gt; AgentState:\n",
       "    # Hardcoded tasks\n",
       "    tasks = <span style=\"color: #008000; text-decoration-color: #008000\">\"1. Analyze requirements\\n2. Develop solution\\n3. Test and deploy\"</span>\n",
       "    \n",
       "    # Simplified email writing\n",
       "    email = f\"<span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>\n",
       "    Dear Client,\n",
       "\n",
       "    Based on your requirements: <span style=\"font-weight: bold\">{</span>state<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'requirements'</span><span style=\"font-weight: bold\">]}</span>\n",
       "\n",
       "    We propose the following tasks:\n",
       "    <span style=\"font-weight: bold\">{</span>tasks<span style=\"font-weight: bold\">}</span>\n",
       "\n",
       "    Best regards,\n",
       "    AI Team\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>\"\n",
       "    return <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"email\"</span>: email<span style=\"font-weight: bold\">}</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Executing function code for write_email:\n",
       "def \u001b[1;35mwrite_email\u001b[0m\u001b[1m(\u001b[0mstate: AgentState\u001b[1m)\u001b[0m -> AgentState:\n",
       "    # Hardcoded tasks\n",
       "    tasks = \u001b[32m\"1. Analyze requirements\\n2. Develop solution\\n3. Test and deploy\"\u001b[0m\n",
       "    \n",
       "    # Simplified email writing\n",
       "    email = f\"\u001b[32m\"\"\u001b[0m\n",
       "    Dear Client,\n",
       "\n",
       "    Based on your requirements: \u001b[1m{\u001b[0mstate\u001b[1m[\u001b[0m\u001b[32m'requirements'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m\n",
       "\n",
       "    We propose the following tasks:\n",
       "    \u001b[1m{\u001b[0mtasks\u001b[1m}\u001b[0m\n",
       "\n",
       "    Best regards,\n",
       "    AI Team\n",
       "    \u001b[32m\"\"\u001b[0m\"\n",
       "    return \u001b[1m{\u001b[0m\u001b[32m\"email\"\u001b[0m: email\u001b[1m}\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">State after forward pass: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'requirements'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Set up a data analytics pipeline'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'email'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'\\n    Dear Client,\\n\\n    </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Based on your requirements: Set up a data analytics pipeline\\n\\n    We propose the following tasks:\\n    1. Analyze</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">requirements\\n2. Develop solution\\n3. Test and deploy\\n\\n    Best regards,\\n    AI Team\\n    '</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "State after forward pass: \u001b[1m{\u001b[0m\u001b[32m'requirements'\u001b[0m: \u001b[32m'Set up a data analytics pipeline'\u001b[0m, \u001b[32m'email'\u001b[0m: \u001b[32m'\\n    Dear Client,\\n\\n    \u001b[0m\n",
       "\u001b[32mBased on your requirements: Set up a data analytics pipeline\\n\\n    We propose the following tasks:\\n    1. Analyze\u001b[0m\n",
       "\u001b[32mrequirements\\n2. Develop solution\\n3. Test and deploy\\n\\n    Best regards,\\n    AI Team\\n    '\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Output for example <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'requirements'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Set up a data analytics pipeline'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'email'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'\\n    Dear Client,\\n\\n    </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Based on your requirements: Set up a data analytics pipeline\\n\\n    We propose the following tasks:\\n    1. Analyze</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">requirements\\n2. Develop solution\\n3. Test and deploy\\n\\n    Best regards,\\n    AI Team\\n    '</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Output for example \u001b[1;36m3\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'requirements'\u001b[0m: \u001b[32m'Set up a data analytics pipeline'\u001b[0m, \u001b[32m'email'\u001b[0m: \u001b[32m'\\n    Dear Client,\\n\\n    \u001b[0m\n",
       "\u001b[32mBased on your requirements: Set up a data analytics pipeline\\n\\n    We propose the following tasks:\\n    1. Analyze\u001b[0m\n",
       "\u001b[32mrequirements\\n2. Develop solution\\n3. Test and deploy\\n\\n    Best regards,\\n    AI Team\\n    '\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Raw LLM response:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Raw LLM response:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Here is the comparison of the generated output with the ground truth output:\n",
       "\n",
       "**requirements** score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span>\n",
       "**requirements** feedback: The generated output is partially correct, but it lacks the detail of <span style=\"color: #008000; text-decoration-color: #008000\">\"Analyze data </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">sources and requirements\"</span> which is a crucial step in setting up a data analytics pipeline.\n",
       "\n",
       "**email** score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8</span>\n",
       "**email** feedback: The generated output is mostly correct, but it lacks the details of tasks <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, and <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> which are\n",
       "essential for a complete data analytics pipeline. Additionally, the tone and language used in the generated output \n",
       "is somewhat informal and lacks the professionalism of the ground truth output.\n",
       "\n",
       "**email** score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span> <span style=\"font-weight: bold\">(</span>for the specific task list<span style=\"font-weight: bold\">)</span>\n",
       "**email** feedback: The generated output is completely wrong for the task list, as it only includes three tasks \n",
       "whereas the ground truth output includes five tasks.\n",
       "\n",
       "Note: The scores are subjective and based on the comparison of the generated output with the ground truth output. \n",
       "The scores can be adjusted based on the specific requirements and criteria of the evaluation.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Here is the comparison of the generated output with the ground truth output:\n",
       "\n",
       "**requirements** score: \u001b[1;36m0.5\u001b[0m\n",
       "**requirements** feedback: The generated output is partially correct, but it lacks the detail of \u001b[32m\"Analyze data \u001b[0m\n",
       "\u001b[32msources and requirements\"\u001b[0m which is a crucial step in setting up a data analytics pipeline.\n",
       "\n",
       "**email** score: \u001b[1;36m0.8\u001b[0m\n",
       "**email** feedback: The generated output is mostly correct, but it lacks the details of tasks \u001b[1;36m3\u001b[0m, \u001b[1;36m4\u001b[0m, and \u001b[1;36m5\u001b[0m which are\n",
       "essential for a complete data analytics pipeline. Additionally, the tone and language used in the generated output \n",
       "is somewhat informal and lacks the professionalism of the ground truth output.\n",
       "\n",
       "**email** score: \u001b[1;36m0.2\u001b[0m \u001b[1m(\u001b[0mfor the specific task list\u001b[1m)\u001b[0m\n",
       "**email** feedback: The generated output is completely wrong for the task list, as it only includes three tasks \n",
       "whereas the ground truth output includes five tasks.\n",
       "\n",
       "Note: The scores are subjective and based on the comparison of the generated output with the ground truth output. \n",
       "The scores can be adjusted based on the specific requirements and criteria of the evaluation.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Warning: Could not find score or feedback for write_email\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Warning: Could not find score or feedback for write_email\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Updating node function for write_email\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Updating node function for write_email\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Updating node: write_email\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Updating node: write_email\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Original function:\n",
       "def <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">write_email</span><span style=\"font-weight: bold\">(</span>state: AgentState<span style=\"font-weight: bold\">)</span> -&gt; AgentState:\n",
       "    # Hardcoded tasks\n",
       "    tasks = <span style=\"color: #008000; text-decoration-color: #008000\">\"1. Analyze requirements\\n2. Develop solution\\n3. Test and deploy\"</span>\n",
       "    \n",
       "    # Simplified email writing\n",
       "    email = f\"<span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>\n",
       "    Dear Client,\n",
       "\n",
       "    Based on your requirements: <span style=\"font-weight: bold\">{</span>state<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'requirements'</span><span style=\"font-weight: bold\">]}</span>\n",
       "\n",
       "    We propose the following tasks:\n",
       "    <span style=\"font-weight: bold\">{</span>tasks<span style=\"font-weight: bold\">}</span>\n",
       "\n",
       "    Best regards,\n",
       "    AI Team\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>\"\n",
       "    return <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"email\"</span>: email<span style=\"font-weight: bold\">}</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Original function:\n",
       "def \u001b[1;35mwrite_email\u001b[0m\u001b[1m(\u001b[0mstate: AgentState\u001b[1m)\u001b[0m -> AgentState:\n",
       "    # Hardcoded tasks\n",
       "    tasks = \u001b[32m\"1. Analyze requirements\\n2. Develop solution\\n3. Test and deploy\"\u001b[0m\n",
       "    \n",
       "    # Simplified email writing\n",
       "    email = f\"\u001b[32m\"\"\u001b[0m\n",
       "    Dear Client,\n",
       "\n",
       "    Based on your requirements: \u001b[1m{\u001b[0mstate\u001b[1m[\u001b[0m\u001b[32m'requirements'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m\n",
       "\n",
       "    We propose the following tasks:\n",
       "    \u001b[1m{\u001b[0mtasks\u001b[1m}\u001b[0m\n",
       "\n",
       "    Best regards,\n",
       "    AI Team\n",
       "    \u001b[32m\"\"\u001b[0m\"\n",
       "    return \u001b[1m{\u001b[0m\u001b[32m\"email\"\u001b[0m: email\u001b[1m}\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Score: \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Feedback: \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Feedback: \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'Input to ChatPromptTemplate is missing variables {\\'input\\', \\'tasks\\', \\'\"email\"\\', \\'output\\', \\'\\\\n                        \"input\"\\', \"state[\\'requirements\\']\"}.  Expected: [\\'\\\\n                        \"input\"\\', \\'\"email\"\\', \\'input\\', \\'output\\', \"state[\\'requirements\\']\", \\'tasks\\'] Received: [\\'original_function\\', \\'score\\', \\'feedback\\']'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 291\u001b[0m\n\u001b[1;32m    289\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m GraphAgentOptimizer(graph, ground_truth, llm)\n\u001b[1;32m    290\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mload_graph()\n\u001b[0;32m--> 291\u001b[0m optimized_graph \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# # Test the optimized graph\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# test_input = {\"requirements\": \"Design a customer loyalty program for a retail chain\"}\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;66;03m# result = optimized_graph.invoke(test_input)\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;66;03m# print(result)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[63], line 133\u001b[0m, in \u001b[0;36mGraphAgentOptimizer.optimize\u001b[0;34m(self, num_iterations)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    132\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError processing example \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 133\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_node_functions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[63], line 194\u001b[0m, in \u001b[0;36mGraphAgentOptimizer.update_node_functions\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m performance[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.8\u001b[39m:\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpdating node function for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 194\u001b[0m     updated_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_function_updater\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnode_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_functions\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnode_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mperformance\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mperformance\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfeedback\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_functions[node_name] \u001b[38;5;241m=\u001b[39m updated_function\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpdated function for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mupdated_function\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[63], line 86\u001b[0m, in \u001b[0;36mNodeFunctionUpdater.update\u001b[0;34m(self, node_name, original_function, score, feedback)\u001b[0m\n\u001b[1;32m     84\u001b[0m prompt \u001b[38;5;241m=\u001b[39m ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(prompt_template)\n\u001b[1;32m     85\u001b[0m chain \u001b[38;5;241m=\u001b[39m prompt \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\n\u001b[0;32m---> 86\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moriginal_function\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfeedback\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeedback\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLLM response content:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mcontent)\n",
      "File \u001b[0;32m~/mambaforge/envs/dspy/lib/python3.11/site-packages/langchain_core/runnables/base.py:2399\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   2397\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2398\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[0;32m-> 2399\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2400\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2401\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[1;32m   2402\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2403\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2404\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2405\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2406\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   2407\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/mambaforge/envs/dspy/lib/python3.11/site-packages/langchain_core/prompts/base.py:128\u001b[0m, in \u001b[0;36mBasePromptTemplate.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags:\n\u001b[1;32m    127\u001b[0m     config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags\n\u001b[0;32m--> 128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_format_prompt_with_error_handling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/dspy/lib/python3.11/site-packages/langchain_core/runnables/base.py:1509\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1505\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m   1506\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(var_child_runnable_config\u001b[38;5;241m.\u001b[39mset, child_config)\n\u001b[1;32m   1507\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m   1508\u001b[0m         Output,\n\u001b[0;32m-> 1509\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1510\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1511\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1512\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1513\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1514\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1515\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1516\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1517\u001b[0m     )\n\u001b[1;32m   1518\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1519\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/mambaforge/envs/dspy/lib/python3.11/site-packages/langchain_core/runnables/config.py:346\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    345\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/dspy/lib/python3.11/site-packages/langchain_core/prompts/base.py:111\u001b[0m, in \u001b[0;36mBasePromptTemplate._format_prompt_with_error_handling\u001b[0;34m(self, inner_input)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_format_prompt_with_error_handling\u001b[39m(\u001b[38;5;28mself\u001b[39m, inner_input: Dict) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PromptValue:\n\u001b[0;32m--> 111\u001b[0m     _inner_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_prompt(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_inner_input)\n",
      "File \u001b[0;32m~/mambaforge/envs/dspy/lib/python3.11/site-packages/langchain_core/prompts/base.py:103\u001b[0m, in \u001b[0;36mBasePromptTemplate._validate_input\u001b[0;34m(self, inner_input)\u001b[0m\n\u001b[1;32m    101\u001b[0m missing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_variables)\u001b[38;5;241m.\u001b[39mdifference(inner_input)\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is missing variables \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Expected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_variables\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(inner_input\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    107\u001b[0m     )\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inner_input\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Input to ChatPromptTemplate is missing variables {\\'input\\', \\'tasks\\', \\'\"email\"\\', \\'output\\', \\'\\\\n                        \"input\"\\', \"state[\\'requirements\\']\"}.  Expected: [\\'\\\\n                        \"input\"\\', \\'\"email\"\\', \\'input\\', \\'output\\', \"state[\\'requirements\\']\", \\'tasks\\'] Received: [\\'original_function\\', \\'score\\', \\'feedback\\']'"
     ]
    }
   ],
   "source": [
    "from rich import print\n",
    "import inspect\n",
    "from typing import List, Dict, Any, Callable, TypedDict\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    requirements: str\n",
    "    email: str\n",
    "\n",
    "\n",
    "class NodeFunctionUpdater:\n",
    "    def __init__(self, llm: ChatOpenAI):\n",
    "        self.llm = llm\n",
    "\n",
    "    def update(self, node_name: str, original_function: str, score: float, feedback: str) -> str:\n",
    "        print(f\"Updating node: {node_name}\")\n",
    "        print(f\"Original function:\\n{original_function}\")\n",
    "        print(f\"Score: {score}\")\n",
    "        print(f\"Feedback: {feedback}\")\n",
    "\n",
    "        prompt_template = f\"\"\"\n",
    "        You are an expert in optimizing Python functions. I have a function that needs to be improved based on the \n",
    "        performance score and feedback provided. Please rewrite the function following the template provided below.\n",
    "\n",
    "        Original function:\n",
    "        ```\n",
    "        {original_function}\n",
    "        ```\n",
    "\n",
    "        Performance score: {score}\n",
    "        Feedback: {feedback}\n",
    "\n",
    "        The improved function should follow this template:\n",
    "\n",
    "        def {node_name}(state: AgentState) -> AgentState:\n",
    "            def updated_node() -> ChatPromptTemplate:\n",
    "                examples = [\n",
    "                    {{\n",
    "                        \"input\": textwrap.dedent('''\n",
    "                        [HERE GOES THE INPUT 1]\n",
    "                        '''),\n",
    "                        \"output\": textwrap.dedent('''\n",
    "                        [HERE GOES THE OUTPUT 1]            \n",
    "                        ''')\n",
    "                    }},\n",
    "                    {{\n",
    "                        \"input\": textwrap.dedent('''\n",
    "                        [HERE GOES THE INPUT 2]\n",
    "                        '''),\n",
    "                        \"output\": textwrap.dedent('''\n",
    "                        [HERE GOES THE OUTPUT 2] \n",
    "                        ''')\n",
    "                    }}\n",
    "                ]\n",
    "                \n",
    "                example_prompt = ChatPromptTemplate.from_messages(\n",
    "                    [\n",
    "                        (\"human\", \"{{input}}\"),\n",
    "                        (\"ai\", \"{{output}}\"),\n",
    "                    ]\n",
    "                )\n",
    "                \n",
    "                few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "                    example_prompt=example_prompt,\n",
    "                    examples=examples,\n",
    "                )\n",
    "                system_prompt = textwrap.dedent('''\n",
    "                [HERE GOES THE SYSTEM PROMPT]\n",
    "                ''')\n",
    "                final_prompt = ChatPromptTemplate.from_messages(\n",
    "                    [\n",
    "                        (\"system\", system_prompt),\n",
    "                        few_shot_prompt,\n",
    "                        (\"human\", \"{{input}}\"),\n",
    "                    ]\n",
    "                )\n",
    "                return final_prompt\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "        chain = prompt | self.llm\n",
    "        response = chain.invoke({\n",
    "            \"original_function\": original_function,\n",
    "            \"score\": score,\n",
    "            \"feedback\": feedback\n",
    "        })\n",
    "        print(\"LLM response content:\")\n",
    "        print(response.content)\n",
    "        return response.content\n",
    "\n",
    "\n",
    "class GraphAgentOptimizer:\n",
    "    def __init__(self, original_graph: StateGraph, ground_truth: List[Dict[str, Any]], llm: ChatOpenAI):\n",
    "        self.original_graph = original_graph\n",
    "        self.ground_truth = ground_truth\n",
    "        self.llm = llm\n",
    "        self.node_functions = {}\n",
    "        self.node_performances = {}\n",
    "        self.node_function_updater = NodeFunctionUpdater(llm)\n",
    "\n",
    "    def load_graph(self):\n",
    "        print(\"Loading graph...\")\n",
    "        for node_name, node_func in self.original_graph.nodes.items():\n",
    "            self.node_functions[node_name] = self.extract_function_source(node_func)\n",
    "            self.node_performances[node_name] = {'score': 0, 'feedback': ''}\n",
    "        print(\"Graph loaded successfully.\")\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_function_source(func: Callable) -> str:\n",
    "        if hasattr(func, 'func'):  # For RunnableCallable objects\n",
    "            return inspect.getsource(func.func)\n",
    "        elif callable(func):\n",
    "            return inspect.getsource(func)\n",
    "        else:\n",
    "            return str(func)  # Fallback for other types\n",
    "\n",
    "    def optimize(self, num_iterations: int):\n",
    "        for iteration in range(num_iterations):\n",
    "            print(f\"Iteration {iteration + 1}\")\n",
    "            for i, example in enumerate(self.ground_truth):\n",
    "                print(f\"  Processing example {i + 1}\")\n",
    "                try:\n",
    "                    input_data = {\"requirements\": example['input']}  # Adjusted to match expected input structure\n",
    "                    output = self.forward_pass(input_data)\n",
    "                    print(f\"Output for example {i + 1}: {output}\")\n",
    "                    self.evaluate_and_update(output, example['output'])\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing example {i + 1}: {str(e)}\")\n",
    "            self.update_node_functions()\n",
    "\n",
    "    def forward_pass(self, input_data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        print(f\"Starting forward pass with input: {input_data}\")\n",
    "        state = input_data.copy()\n",
    "        for node_name in self.original_graph.nodes:\n",
    "            node_func = self.get_node_function(node_name)\n",
    "            state.update(node_func(state))\n",
    "        print(f\"State after forward pass: {state}\")\n",
    "        return state\n",
    "\n",
    "    def evaluate_and_update(self, generated_output: Dict[str, Any], ground_truth_output: Dict[str, Any]):\n",
    "        prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        Compare the generated output with the ground truth output.\n",
    "        Provide a score from 0 to 1 for each node in the graph,\n",
    "        where 1 is perfect and 0 is completely wrong.\n",
    "        Also provide a brief explanation for each score.\n",
    "\n",
    "        Generated output:\n",
    "        {generated_output}\n",
    "\n",
    "        Ground truth output:\n",
    "        {ground_truth_output}\n",
    "\n",
    "        Response format:\n",
    "        [node_name] score: [score]\n",
    "        [node_name] feedback: [feedback]\n",
    "        (Repeat for each node)\n",
    "        \"\"\")\n",
    "        chain = prompt | self.llm\n",
    "        response = chain.invoke({\n",
    "            \"generated_output\": str(generated_output),\n",
    "            \"ground_truth_output\": str(ground_truth_output)\n",
    "        })\n",
    "\n",
    "        print(\"Raw LLM response:\")\n",
    "        print(response.content)\n",
    "\n",
    "        lines = response.content.split('\\n')\n",
    "        for node_name in self.node_functions.keys():\n",
    "            score_line = next((line for line in lines if f\"{node_name} score:\" in line), None)\n",
    "            feedback_line = next((line for line in lines if f\"{node_name} feedback:\" in line), None)\n",
    "\n",
    "            if score_line and feedback_line:\n",
    "                try:\n",
    "                    score = float(score_line.split(':')[1].strip())\n",
    "                except ValueError:\n",
    "                    print(f\"Warning: Could not parse score for {node_name}. Using default score of 0.5\")\n",
    "                    score = 0.5\n",
    "\n",
    "                feedback = feedback_line.split(':', 1)[1].strip() if ':' in feedback_line else ''\n",
    "\n",
    "                self.node_performances[node_name]['score'] = (self.node_performances[node_name]['score'] + score) / 2\n",
    "                self.node_performances[node_name]['feedback'] += feedback + '\\n'\n",
    "            else:\n",
    "                print(f\"Warning: Could not find score or feedback for {node_name}\")\n",
    "\n",
    "    def update_node_functions(self):\n",
    "        for node_name, performance in self.node_performances.items():\n",
    "            if performance['score'] < 0.8:\n",
    "                print(f\"Updating node function for {node_name}\")\n",
    "                updated_function = self.node_function_updater.update(\n",
    "                    node_name,\n",
    "                    self.node_functions[node_name],\n",
    "                    performance['score'],\n",
    "                    performance['feedback']\n",
    "                )\n",
    "                self.node_functions[node_name] = updated_function\n",
    "                print(f\"Updated function for {node_name}:\\n{updated_function}\")\n",
    "\n",
    "    def get_node_function(self, node_name: str) -> Callable:\n",
    "        function_code = self.node_functions[node_name]\n",
    "        print(f\"Executing function code for {node_name}:\\n{function_code}\")\n",
    "        exec(function_code, globals())\n",
    "        return eval(node_name)\n",
    "\n",
    "    def export_optimized_graph(self) -> StateGraph:\n",
    "        optimized_graph = StateGraph(self.original_graph.state_type)\n",
    "        for node_name, node_func in self.node_functions.items():\n",
    "            optimized_graph.add_node(node_name, self.get_node_function(node_name))\n",
    "\n",
    "        for edge in self.original_graph.edges:\n",
    "            optimized_graph.add_edge(edge.start, edge.end)\n",
    "\n",
    "        for conditional_edge in self.original_graph.conditional_edges:\n",
    "            optimized_graph.add_conditional_edges(\n",
    "                conditional_edge.start,\n",
    "                conditional_edge.condition,\n",
    "                conditional_edge.edge_map\n",
    "            )\n",
    "\n",
    "        optimized_graph.set_entry_point(self.original_graph.entry_point)\n",
    "\n",
    "        return optimized_graph.compile()\n",
    "\n",
    "# Usage\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "ground_truth = [\n",
    "    {\n",
    "        \"input\": \"Develop a website with user authentication\",\n",
    "        \"output\": \"\"\"\n",
    "        Dear Client,\n",
    "\n",
    "        Based on your requirements: Develop a website with user authentication\n",
    "\n",
    "        We propose the following tasks:\n",
    "        1. Design user authentication system\n",
    "        2. Develop frontend and backend\n",
    "        3. Implement security measures\n",
    "        4. Test and deploy website\n",
    "\n",
    "        Best regards,\n",
    "        AI Team\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Create a mobile app for task management\",\n",
    "        \"output\": \"\"\"\n",
    "        Dear Client,\n",
    "\n",
    "        Based on your requirements: Create a mobile app for task management\n",
    "\n",
    "        We propose the following tasks:\n",
    "        1. Design app UI/UX\n",
    "        2. Develop task management features\n",
    "        3. Implement data synchronization\n",
    "        4. Test on multiple devices\n",
    "        5. Deploy to app stores\n",
    "\n",
    "        Best regards,\n",
    "        AI Team\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Set up a data analytics pipeline\",\n",
    "        \"output\": \"\"\"\n",
    "        Dear Client,\n",
    "\n",
    "        Based on your requirements: Set up a data analytics pipeline\n",
    "\n",
    "        We propose the following tasks:\n",
    "        1. Analyze data sources and requirements\n",
    "        2. Design data pipeline architecture\n",
    "        3. Implement data collection and processing\n",
    "        4. Set up analytics and visualization tools\n",
    "        5. Test and optimize pipeline performance\n",
    "\n",
    "        Best regards,\n",
    "        AI Team\n",
    "        \"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "llm_name = \"llama-3.1-8b-instant\"\n",
    "llm = ChatGroq(cache=False, temperature=0.0, model_name=llm_name)\n",
    "optimizer = GraphAgentOptimizer(graph, ground_truth, llm)\n",
    "optimizer.load_graph()\n",
    "optimized_graph = optimizer.optimize(num_iterations=1)\n",
    "\n",
    "\n",
    "# # Test the optimized graph\n",
    "# test_input = {\"requirements\": \"Design a customer loyalty program for a retail chain\"}\n",
    "# result = optimized_graph.invoke(test_input)\n",
    "# print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">def <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">write_email</span><span style=\"font-weight: bold\">(</span>state: AgentState<span style=\"font-weight: bold\">)</span> -&gt; AgentState:\n",
       "    # Hardcoded tasks\n",
       "    tasks = <span style=\"color: #008000; text-decoration-color: #008000\">\"1. Analyze requirements\\n2. Develop solution\\n3. Test and deploy\"</span>\n",
       "    \n",
       "    # Simplified email writing\n",
       "    email = f\"<span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>\n",
       "    Dear Client,\n",
       "\n",
       "    Based on your requirements: <span style=\"font-weight: bold\">{</span>state<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'requirements'</span><span style=\"font-weight: bold\">]}</span>\n",
       "\n",
       "    We propose the following tasks:\n",
       "    <span style=\"font-weight: bold\">{</span>tasks<span style=\"font-weight: bold\">}</span>\n",
       "\n",
       "    Best regards,\n",
       "    AI Team\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>\"\n",
       "    return <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"email\"</span>: email<span style=\"font-weight: bold\">}</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "def \u001b[1;35mwrite_email\u001b[0m\u001b[1m(\u001b[0mstate: AgentState\u001b[1m)\u001b[0m -> AgentState:\n",
       "    # Hardcoded tasks\n",
       "    tasks = \u001b[32m\"1. Analyze requirements\\n2. Develop solution\\n3. Test and deploy\"\u001b[0m\n",
       "    \n",
       "    # Simplified email writing\n",
       "    email = f\"\u001b[32m\"\"\u001b[0m\n",
       "    Dear Client,\n",
       "\n",
       "    Based on your requirements: \u001b[1m{\u001b[0mstate\u001b[1m[\u001b[0m\u001b[32m'requirements'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m\n",
       "\n",
       "    We propose the following tasks:\n",
       "    \u001b[1m{\u001b[0mtasks\u001b[1m}\u001b[0m\n",
       "\n",
       "    Best regards,\n",
       "    AI Team\n",
       "    \u001b[32m\"\"\u001b[0m\"\n",
       "    return \u001b[1m{\u001b[0m\u001b[32m\"email\"\u001b[0m: email\u001b[1m}\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(optimizer.node_functions['write_email'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgraph\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'graph' is not defined"
     ]
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dspy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
